{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy\n",
    "from tensorflow import keras\n",
    "\n",
    "SHUFFLE_BUFFER = 500\n",
    "BATCH_SIZE = 36\n",
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/prepared_data.csv')\n",
    "\n",
    "TRAINING_SIZE = math.floor(0.5*len(data))\n",
    "TEST_SIZE = math.floor(0.3*len(data))\n",
    "EVALUATION_SIZE = math.floor(0.2*len(data))\n",
    "\n",
    "indices = (TRAINING_SIZE, TRAINING_SIZE+TEST_SIZE, TRAINING_SIZE+TEST_SIZE+EVALUATION_SIZE)\n",
    "inputs = ['ra', 'dec', 'u', 'g', 'r', 'i', 'z', 'redshift']\n",
    "outputs = ['class_GALAXY','class_QSO','class_STAR']\n",
    "\n",
    "training = data[0:indices[0]]\n",
    "test = data[indices[0]:indices[1]]\n",
    "evaluation = data[indices[1]:indices[2]]\n",
    "professor = {\n",
    "\t\"training\": {\n",
    "\t\t\"questions\": training[inputs],\n",
    "\t\t\"answers\": training[outputs]\n",
    "\t},\n",
    "\t\"test\": {\n",
    "\t\t\"questions\": test[inputs],\n",
    "\t\t\"answers\": test[outputs]\n",
    "\t},\n",
    "\t\"evaluation\": {\n",
    "\t\t\"questions\": evaluation[inputs],\n",
    "\t\t\"answers\": evaluation[outputs]\n",
    "\t}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cgd(tups):\n",
    "\tprint(tups)\n",
    "\treturn tups\n",
    "class CGD(tf.keras.optimizers.SGD):\n",
    "\tdef __init__(self) -> None:\n",
    "\t    super().__init__()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "139/139 [==============================] - 1s 2ms/step - loss: 0.7016 - accuracy: 0.4066 - val_loss: 0.6673 - val_accuracy: 0.3737\n",
      "Epoch 2/30\n",
      "139/139 [==============================] - 0s 2ms/step - loss: 0.6523 - accuracy: 0.4144 - val_loss: 0.6394 - val_accuracy: 0.4257\n",
      "Epoch 3/30\n",
      "139/139 [==============================] - 0s 1ms/step - loss: 0.6282 - accuracy: 0.4822 - val_loss: 0.6231 - val_accuracy: 0.4487\n",
      "Epoch 4/30\n",
      "139/139 [==============================] - 0s 3ms/step - loss: 0.6137 - accuracy: 0.4902 - val_loss: 0.6122 - val_accuracy: 0.4493\n",
      "Epoch 5/30\n",
      "139/139 [==============================] - 0s 2ms/step - loss: 0.6038 - accuracy: 0.4968 - val_loss: 0.6041 - val_accuracy: 0.4703\n",
      "Epoch 6/30\n",
      "139/139 [==============================] - 0s 1ms/step - loss: 0.5966 - accuracy: 0.5304 - val_loss: 0.5979 - val_accuracy: 0.4983\n",
      "Epoch 7/30\n",
      "139/139 [==============================] - 0s 1ms/step - loss: 0.5910 - accuracy: 0.5668 - val_loss: 0.5928 - val_accuracy: 0.5337\n",
      "Epoch 8/30\n",
      "139/139 [==============================] - 0s 1ms/step - loss: 0.5863 - accuracy: 0.6070 - val_loss: 0.5882 - val_accuracy: 0.5723\n",
      "Epoch 9/30\n",
      "139/139 [==============================] - 0s 1ms/step - loss: 0.5821 - accuracy: 0.6460 - val_loss: 0.5838 - val_accuracy: 0.6093\n",
      "Epoch 10/30\n",
      "139/139 [==============================] - 0s 1ms/step - loss: 0.5780 - accuracy: 0.6786 - val_loss: 0.5797 - val_accuracy: 0.6433\n",
      "Epoch 11/30\n",
      "139/139 [==============================] - 0s 1ms/step - loss: 0.5740 - accuracy: 0.6986 - val_loss: 0.5755 - val_accuracy: 0.6630\n",
      "Epoch 12/30\n",
      "139/139 [==============================] - 0s 1ms/step - loss: 0.5700 - accuracy: 0.7104 - val_loss: 0.5714 - val_accuracy: 0.6810\n",
      "Epoch 13/30\n",
      "139/139 [==============================] - 0s 2ms/step - loss: 0.5660 - accuracy: 0.7240 - val_loss: 0.5672 - val_accuracy: 0.6923\n",
      "Epoch 14/30\n",
      "139/139 [==============================] - 0s 3ms/step - loss: 0.5619 - accuracy: 0.7374 - val_loss: 0.5629 - val_accuracy: 0.7050\n",
      "Epoch 15/30\n",
      "139/139 [==============================] - 1s 4ms/step - loss: 0.5577 - accuracy: 0.7456 - val_loss: 0.5584 - val_accuracy: 0.7190\n",
      "Epoch 16/30\n",
      "139/139 [==============================] - 0s 3ms/step - loss: 0.5533 - accuracy: 0.7616 - val_loss: 0.5539 - val_accuracy: 0.7323\n",
      "Epoch 17/30\n",
      "139/139 [==============================] - 0s 2ms/step - loss: 0.5490 - accuracy: 0.7688 - val_loss: 0.5494 - val_accuracy: 0.7470\n",
      "Epoch 18/30\n",
      "139/139 [==============================] - 0s 3ms/step - loss: 0.5446 - accuracy: 0.7820 - val_loss: 0.5449 - val_accuracy: 0.7640\n",
      "Epoch 19/30\n",
      "139/139 [==============================] - 0s 3ms/step - loss: 0.5403 - accuracy: 0.7910 - val_loss: 0.5404 - val_accuracy: 0.7750\n",
      "Epoch 20/30\n",
      "139/139 [==============================] - 0s 2ms/step - loss: 0.5360 - accuracy: 0.8010 - val_loss: 0.5361 - val_accuracy: 0.7803\n",
      "Epoch 21/30\n",
      "139/139 [==============================] - 0s 2ms/step - loss: 0.5318 - accuracy: 0.8016 - val_loss: 0.5316 - val_accuracy: 0.7867\n",
      "Epoch 22/30\n",
      "139/139 [==============================] - 0s 2ms/step - loss: 0.5276 - accuracy: 0.8080 - val_loss: 0.5272 - val_accuracy: 0.7953\n",
      "Epoch 23/30\n",
      "139/139 [==============================] - 0s 2ms/step - loss: 0.5234 - accuracy: 0.8116 - val_loss: 0.5228 - val_accuracy: 0.8013\n",
      "Epoch 24/30\n",
      "139/139 [==============================] - 0s 2ms/step - loss: 0.5193 - accuracy: 0.8136 - val_loss: 0.5185 - val_accuracy: 0.8053\n",
      "Epoch 25/30\n",
      "139/139 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.8142 - val_loss: 0.5140 - val_accuracy: 0.8117\n",
      "Epoch 26/30\n",
      "139/139 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.8172 - val_loss: 0.5094 - val_accuracy: 0.8180\n",
      "Epoch 27/30\n",
      "139/139 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.8228 - val_loss: 0.5049 - val_accuracy: 0.8217\n",
      "Epoch 28/30\n",
      "139/139 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.8274 - val_loss: 0.5002 - val_accuracy: 0.8290\n",
      "Epoch 29/30\n",
      "139/139 [==============================] - 0s 4ms/step - loss: 0.4979 - accuracy: 0.8336 - val_loss: 0.4956 - val_accuracy: 0.8327\n",
      "Epoch 30/30\n",
      "139/139 [==============================] - 0s 2ms/step - loss: 0.4936 - accuracy: 0.8380 - val_loss: 0.4910 - val_accuracy: 0.8353\n"
     ]
    }
   ],
   "source": [
    "normalizer = keras.layers.Normalization(axis=-1)\n",
    "normalizer.adapt(data[['ra', 'dec', 'u', 'g', 'r', 'i', 'z', 'redshift']])\n",
    "\n",
    "model = keras.Sequential([\n",
    "\tnormalizer,\n",
    "\tkeras.layers.Dense(9, activation='relu'),\n",
    "\tkeras.layers.Dense(9, activation='relu'),\n",
    "\tkeras.layers.Dense(3, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(\n",
    "\tCGD(),\n",
    "\tloss=keras.losses.BinaryCrossentropy(),\n",
    "\tmetrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(professor['training']['questions'], professor['training']['answers'], validation_data=(professor['test']['questions'], professor['test']['answers']), epochs=EPOCHS, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "normalization_4 (Normalizati (None, 8)                 17        \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 9)                 81        \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 3)                 30        \n",
      "=================================================================\n",
      "Total params: 218\n",
      "Trainable params: 201\n",
      "Non-trainable params: 17\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>u</th>\n",
       "      <th>g</th>\n",
       "      <th>r</th>\n",
       "      <th>i</th>\n",
       "      <th>z</th>\n",
       "      <th>redshift</th>\n",
       "      <th>class_GALAXY</th>\n",
       "      <th>class_QSO</th>\n",
       "      <th>class_STAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8000</th>\n",
       "      <td>8000</td>\n",
       "      <td>0.190349</td>\n",
       "      <td>-0.599724</td>\n",
       "      <td>-0.079026</td>\n",
       "      <td>-0.204305</td>\n",
       "      <td>-0.154887</td>\n",
       "      <td>-0.110684</td>\n",
       "      <td>-0.030056</td>\n",
       "      <td>-0.370001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8001</th>\n",
       "      <td>8001</td>\n",
       "      <td>0.188651</td>\n",
       "      <td>-0.598305</td>\n",
       "      <td>0.745707</td>\n",
       "      <td>0.702019</td>\n",
       "      <td>0.629892</td>\n",
       "      <td>0.602372</td>\n",
       "      <td>0.601848</td>\n",
       "      <td>-0.367239</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8002</th>\n",
       "      <td>8002</td>\n",
       "      <td>0.190667</td>\n",
       "      <td>-0.604786</td>\n",
       "      <td>1.004693</td>\n",
       "      <td>0.648648</td>\n",
       "      <td>0.312791</td>\n",
       "      <td>0.092810</td>\n",
       "      <td>-0.032583</td>\n",
       "      <td>-0.091988</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8003</th>\n",
       "      <td>8003</td>\n",
       "      <td>0.191552</td>\n",
       "      <td>-0.603357</td>\n",
       "      <td>0.394077</td>\n",
       "      <td>1.518491</td>\n",
       "      <td>1.645257</td>\n",
       "      <td>1.595851</td>\n",
       "      <td>1.568480</td>\n",
       "      <td>3.531147</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8004</th>\n",
       "      <td>8004</td>\n",
       "      <td>0.191230</td>\n",
       "      <td>-0.598623</td>\n",
       "      <td>-1.215336</td>\n",
       "      <td>-1.586335</td>\n",
       "      <td>-1.722162</td>\n",
       "      <td>-1.761351</td>\n",
       "      <td>-1.850619</td>\n",
       "      <td>-0.164494</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0        ra       dec         u         g         r         i  \\\n",
       "8000        8000  0.190349 -0.599724 -0.079026 -0.204305 -0.154887 -0.110684   \n",
       "8001        8001  0.188651 -0.598305  0.745707  0.702019  0.629892  0.602372   \n",
       "8002        8002  0.190667 -0.604786  1.004693  0.648648  0.312791  0.092810   \n",
       "8003        8003  0.191552 -0.603357  0.394077  1.518491  1.645257  1.595851   \n",
       "8004        8004  0.191230 -0.598623 -1.215336 -1.586335 -1.722162 -1.761351   \n",
       "\n",
       "             z  redshift  class_GALAXY  class_QSO  class_STAR  \n",
       "8000 -0.030056 -0.370001           0.1        0.1         0.9  \n",
       "8001  0.601848 -0.367239           0.1        0.1         0.9  \n",
       "8002 -0.032583 -0.091988           0.9        0.1         0.1  \n",
       "8003  1.568480  3.531147           0.1        0.9         0.1  \n",
       "8004 -1.850619 -0.164494           0.9        0.1         0.1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 3), dtype=float32, numpy=\n",
       "array([[0.4587853 , 0.10058913, 0.61893904],\n",
       "       [0.45474654, 0.10623825, 0.54063606],\n",
       "       [0.65270674, 0.23475322, 0.21395564],\n",
       "       [0.25587186, 0.91146755, 0.05107963],\n",
       "       [0.5326971 , 0.10572505, 0.40753046]], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.__call__(professor['evaluation']['questions'].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_model(input_shape=11, output_shape=3):\n",
    "#     m = keras.Sequential(\n",
    "#         [\n",
    "#             tf.keras.layers.Dense(40, activation='relu', input_dim=input_shape),  # input shape required\n",
    "#             tf.keras.layers.Dense(40, activation='relu'),\n",
    "#             tf.keras.layers.Dense(20, activation='relu'),\n",
    "#             tf.keras.layers.Dense(output_shape, activation='softmax')\n",
    "#         ]\n",
    "#     )\n",
    "#     return m\n",
    "# lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "#     initial_learning_rate=3e-5,\n",
    "#     decay_steps=10000,\n",
    "#     decay_rate=0.9\n",
    "# )\n",
    "# optimizer = keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "# # Instantiate a loss function.\n",
    "# loss_fn = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "# model = create_model(8)\n",
    "# model.compile(loss=loss_fn, optimizer='sgd', metrics=[\"accuracy\"])\n",
    "# history = model.fit(professor['training']['questions'], professor['training']['answers'], validation_data=(professor['test']['questions'], professor['test']['answers']), batch_size=36, epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13c419340>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Training and Validation Accuracy')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAAHiCAYAAADbK6SdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABO10lEQVR4nO3deXxU1d3H8c/JZF8hJAQIhEV2xLBEQHEBUavV4r5gtVpbtT5aqz6tj1WrdrHa1rbazdaqdZe6VETFDUSwoLIIyL4HSAghJCSZ7JmZ8/xxJ2GICQRIMpnJ9/165ZXMzJ07v7kM+eace+45xlqLiIiIBE9EsAsQERHp6hTGIiIiQaYwFhERCTKFsYiISJApjEVERIJMYSwiIhJkCmMJScaY94wx17b1tsFkjMk1xpzZDvv9xBjzff/P3zbGfNiabY/idbKMMRXGGNfR1irSVSmMpcP4f1E3fPmMMdUBt799JPuy1p5rrX2urbftjIwxdxtjFjZzf5oxps4Yc3xr92Wtfclae3Yb1XXQHw/W2p3W2kRrrbct9t/M6xljzDZjzLr22L9IMCmMpcP4f1EnWmsTgZ3AtwLue6lhO2NMZPCq7JReBE42xgxscv+VwGpr7Zog1BQMpwE9gUHGmBM78oX1mZT2pjCWoDPGTDHG5Blj/s8Yswf4lzGmuzHmHWNMkTFmv//nvgHPCex6vc4Y819jzKP+bbcbY849ym0HGmMWGmPcxpi5xpi/GmNebKHu1tT4S2PMIv/+PjTGpAU8fo0xZocxptgYc29Lx8damwd8DFzT5KHvAM8fro4mNV9njPlvwO2zjDEbjDFlxpi/ACbgseOMMR/769tnjHnJGNPN/9gLQBbwtr9n4y5jzABjjG0ILmNMH2PMbGNMiTFmizHmhoB9P2iMedUY87z/2Kw1xuS0dAz8rgXeAub4fw58X6OMMR/5X6vQGHOP/36XMeYeY8xW/+ssN8b0a1qrf9umn5NFxpg/GmOKgQcPdTz8z+lnjPmP/9+h2BjzF2NMtL+m0QHb9TTGVBlj0g/zfqULURhLZ9ELSAX6AzfifDb/5b+dBVQDfznE8ycCG4E04LfA08YYcxTbvgwsAXoAD/L1AAzUmhqvAr6L06KLBn4MYIwZCTzh338f/+s1G6B+zwXWYowZBozx13ukx6phH2nAf4D7cI7FVmBy4CbAw/76RgD9cI4J1tprOLh347fNvMRMIM///EuBXxtjzgh4fLp/m27A7EPVbIyJ9+/jJf/XlcaYaP9jScBc4H3/aw0G5vmfeicwA/gmkAxcD1Qd6rgEmAhsAzKAhzjE8TDOefJ3gB3AACATmGmtrfO/x6sD9jsDmGetLWplHdIVWGv1pa8O/wJygTP9P08B6oDYQ2w/BtgfcPsT4Pv+n68DtgQ8Fg9YoNeRbIsTZB4gPuDxF4EXW/memqvxvoDb/wO87//5fpxf1g2PJfiPwZkt7DseKAdO9t9+CHjrKI/Vf/0/fwf4PGA7gxOe329hvxcCK5r7N/TfHuA/lpE4QeUFkgIefxh41v/zg8DcgMdGAtWHOLZXA0X+fccCZcBF/sdmBNbV5HkbgQuaub+x1kMcp52H+fduPB7ASQ31NbPdRJw/XIz/9jLg8vb+P6av0PpSy1g6iyJrbU3DDWNMvDHmH/5u3HJgIdDNtDxSd0/DD9bahpZP4hFu2wcoCbgPYFdLBbeyxj0BP1cF1NQncN/W2kqguKXX8tf0GvAdfyv+28DzR1BHc5rWYANvG2MyjDEzjTH5/v2+iNOCbo2GY+kOuG8HTouxQdNjE2taPjd7LfCqtdbj/5y8wYGu6n44rfrmHOqxwzno3/4wx6MfsMNa62m6E2vtFzjvb4oxZjhOy332UdYkYUphLJ1F0+XD/hcYBky01ibjDN6BgHOa7aAASPV3iTbod4jtj6XGgsB9+1+zx2Ge8xxwOXAWkAS8fYx1NK3BcPD7/TXOv8to/36vbrLPQy35thvnWCYF3JcF5B+mpq/xn/8+A7jaGLPHOOMKLgW+6e9q3wUMauHpu4Djmrm/0v898N+6V5Ntmr6/Qx2PXUDWIf6YeM6//TXA64F/eIqAwlg6ryScc5+lxphU4IH2fkFr7Q6cLsQH/QNvTgK+1U41vg6cb4w5xX/u8xcc/v/jp0Ap8CQHzkceSx3vAqOMMRf7Q+Q2Dg6kJKACKDPGZAI/afL8QloIQWvtLmAx8LAxJtYYcwLwPZzW5JG6BtiE8wfHGP/XUJwu9Rk452p7G2NuN8bEGGOSjDET/c99CvilMWaIcZxgjOlhnfO1+TgB7zLGXE/zoR3oUMdjCc4fN48YYxL87znw/PuLwEU4gfz8URwDCXMKY+msHgPigH3A5ziDczrCt3HO/xUDvwL+DdS2sO1jHGWN1tq1wC04A7AKgP044XKo51icX+T9OfgX+lHVYa3dB1wGPILzfocAiwI2+TkwDuf87Ls4g70CPQzcZ4wpNcb8uJmXmIFzbnY38CbwgLV2bmtqa+Ja4G/W2j2BX8DfgWv9XeFn4fzhtAfYDEz1P/cPwKvAhzjn3J/GOVYAN+AEajEwCuePh0Np8XhY59rqb+F0Qe/E+be8IuDxXcCXOC3rT4/8EEi4axhQICLNMMb8G9hgrW33lrmEN2PMM8Bua+19wa5FOh+FsUgA40wmUQJsB84GZgEnWWtXBLMuCW3GmAHASmCstXZ7cKuRzkjd1CIH64VziUsF8CfgZgWxHAtjzC+BNcDvFMTSErWMRUREgkwtYxERkSBTGIuIiARZ0FYiSUtLswMGDAjWy4uIiHSo5cuX77PWNrtASNDCeMCAASxbtixYLy8iItKhjDE7WnpM3dQiIiJBpjAWEREJMoWxiIhIkCmMRUREgkxhLCIiEmQKYxERkSBTGIuIiASZwlhERCTIFMYiIiJBpjAWEREJMoWxiIhIkCmMRUREgkxhLCIiEmQKYxERkSBTGIuIiASZwlhERCTIFMYiItLleX2WWo83aK8fGbRXFhERaSdlVfUAJMVGEhFhGu/3eH0UV9ZRWF7D5sIKVueXsSa/jHUF5VTVeekWH0XPpBgykmPpnRLLby45AWNMSy/TZhTGIiLSaVXXecnbX0V+aTVVdV5qPV5q6n3UeXxYaxu381rYWVzJpsIKNu+tYF9FLQDGQHJsFClxUVTXeymuqMV34GnERbkY2SeZy3P6kZoQTZG7lsLyGva6aymrdndIEIPCWERE2kFNvZetRRVsLqxgU6Gb6novWanxjV+xUS4273U74VlYQUFZNQHZSq3HS97+ava6a1v9mgnRLgZnJDF1WDqDeybiijCUV9dT5v+KjXLRMymGnsmx9EyKYUBaAselO9sFm8JYRCSM1Hl8VNZ6SImLOqh7tiX1Xh/FFXWUVtdRVlVPaXU95dX11NR7qfX4qKl3WqLumgOhVl7jIT7aRc+kWDKSY+iZFEN1vY+dJVXsKqliR0kl+furG1ugkRGGKFcE1fXNn5PtmRRDv9R4XAGt0NgoF1OGpTM42ctw1276miIiE9OI6NaXyO59iYpLJiJge2MgJS7q6y1ZTx3UuqG2HHyehqMEtha8RbDL7TxeUw7eJsHvioYTLj/sMWwLCmMRkU7GWktFrYe97lr2ltdSEziwyILHZ/0h6QTmXnctW/ytzNx9lXh8liiXIT3RaQWmJkQTmMt1XkuRu5Yidw3FlXUHtUibYwwkxUSSEu909ybHRlFe42HL3n0UuWvx+FO3R0I0/VLjGZfVnYvH9mVoRhJDMhIZ0COBKJehuLKuMbCr67wM7pnI4J6JdIuPdl7I54OClbB1HuQugh0bwF3QfFGxKZB1Ehw3DQZPg9RBTuBuW+A8f9sC57memqP/h4hNURiLiHQFlbUe1hWU81WeM5BoTX5Z4/nR1oow0L9HAoN7JnL2yAx6JMawr8I599lwDjRQZIQhs1ssY/p1IyM5hvSkGLrHR5MSdyBs46JdxERFEOsyRNWVYeK6Q8TXL8Dx+SwlVXXERhoS966AtW/C+rchzwPHnQFmGiROhZgk0krXkLZ7CeN2LYHyfIhOhNhkiEmCukrY9glUFTs7zjgeBk2B9GGQPgK6D4DqEijfDWV5sH+7E7ib3ne2T+oNFXvBeiE6CQaeBiOnO/uO8b+GK/rg4l3RB14/Jtm5HdiyNh13wZHCWESknTTtAi6rrqe0qt45l7rXOZeat7+6cfueSTGMzkzh1CHpTvdvcgw9k2KJj3YdtN/IiAhioyKIiXQRGxVBclwUsVGupi9/5MoLYOsHkPsp7N/hBKa7ALx1Tlhljod+E6DviYCB8nwiyvNJK8uDrfPBvdsJtMFnQmQsbHoPVr3sbOuKPtANnJzptGRrSqF0p9NNHOFynnfcNDhuKiT2bF3NJdtgyzzYsRhSBzr76HsiuKKO/Xh0IGMP1z/RTnJycuyyZcuC8toiIm3J4/WxOr+MRVv28eXOUgrKag7ZBRztimBQegJDMpIY2jORkX2SGZ2ZQs/k2GMrpLIYts2H/blOSzG5D6T0hag42LcJ9m6AovVOyzIq/kCLESD3v7B3rfNzQjqkDXWen5zp3C7eAnlLYe86sL6AFzVOcGaOh1EXwdBznNYmgM8Lu1c63ca15ZCZ4wRlSuaxvc8QZYxZbq3Nae4xtYxFRA6jrLqez7cVs2jLPrbvqyTaFUFslIuYyAjKazx8sb0Yd40zOGhoRiL9usczpl8KPZNiv9YF3C0+it4psUS6WtEFai1UFjmtyrhuX3+81g35y2H7p07g7V4JHKaBFZfqdPm69xwY2OSpg34nwpk/d86/Zhx/cHdt09fcvdJpeSb3cUK/pVZohAv6jne+5JAUxiLS5ZVU1jF/w14+3riXPWU1B3UBF5TVsGpXKT4L8dEuhmQk4fH6GgdPRUcYzj+hN5MHp3HSoB70SIxp3Yt6PVBR6JwDrSl1QrHWDTVlULIdijY4X9X7ne2TekP6cOg5AuqrD26lGpfT4px6j9PN23MEVOxx9l2+29lv2hDn3GtCWstB2xoxSTDw1KN/vjRL3dQi0uVU13lZuauUZbklfLKpiC937sdaSE+KYUjPROo8vsbLepLjoph8XA8mD05jbFZ3oiMjoK4K1r0FK16AnZ9BVIJ/EFASRCcceuCP9ToDjdwFTbp7A8R2cwI1fbgzgMlTeyCcizZCRJS/xTnBadH2PdEZ+SudmrqpRaTL8vks2/ZVsia/jNX5ZSzfsZ81+WWNl+OM6pPMD88YwpkjenJ8nxTn2tyKvbBrCeQtgYoi8CTB9iTYnQSlO2D1605LNnUQTPofJ1QbWrZ1lRzyWiFjnBZqSuaBc7JxqQfCvOGrpdarzx/gzYxsltClMBaRsFNT7+X9NXt4fXkeK3bup9J/mVBMZATjM+N5YGwlk6K20L96PdF1pbAb5wvrjCIu3eHsKCIKEjOgzj8xhPU5o4RHXgjjroH+k4+ty/doKITDksJYREKftdjirRRsXMKirSXM217NnppounVL4e7BdZwQU0B/3y5S3FsxhWugsM55XkqW0zoN1DsbJtzgdP32znZGIvtfg/oqpwu64T6RNqIwFpHQ479kpnLjPNybF5FYtIJEbxl9gMv8X8QA1cA2/3MSM5zzrxN/cOBa2aRerX9NY5zzwSLtQGEsIp3S0twS3lqZT9/u8QztmcCImGJSi5dRtvoDEvM/Jd5bTgKw25fJ4ohxVKWPpdvgiUwemkH3iBr/+Vs3JPVxQjg+NdhvSaRFCmMR6Rw8tbB3Hd6qMuYs28iC1dvIjNjPYDaRHbGFHsbtbGe78b4dQ37qycSNOJOckUO4IDOlU6y8I3K0FMYiElzWwpo3YO7PoWwnLuBbwLf880h4UwezP/UbfBEzkk3RI8gansO5A3sQF90G0z+KdBIKYxEJnh2L4cP7IH85xYlD+Z35Efneblw7ZTRnjhkM8am4YlNIA9KAicGuV6SdKIxFpH1Y68weVZ4PZfnO9/J8/6xQ+XhL83Dt30aJK42HPT/gjX2nMCYrlUcvy2ZQemKwqxfpUApjETl61jozQm392Fn+rjz/wOQXte6AxdwdXiIoiehBni+VfG9PVvkm8UHU+Zx78iDmjMtkeK/k4LwPkSBTGIvIkasqgU8ehg1zoDzPua/HEGeln5gkZ9We6EQqo7ozf3cUMzf52FydTHxqb7LSkslKjScrNZ4pfZK5e1APDb6SLk9hLCJHZv078M4dzkLvw86F037srPTTLatxk8LyGv6+YCuvLNhJTb2PM0dk8LcpgxjfX5cXiTRHYSwirVNVAu/dBatfg16j4Zr/ON8DFJbX8MQnW3l5yU68PsuFYzL5wemDGJKRFKSiRUKDwlhEmldfDbtXOEv17VriLD5fVwlT74VT7jhoDduNe9y8+PkO/r1sF16f5ZJxmdw6dQhZPeKD+AZEQofCWEQOqC6Fje/B2jdh23zw+udw7j4Qhp4DJ9/a2BqurvPy7uoCXlmyk+U79hPtiuCCMX344RkKYZEjpTAW6ep8Ptj8ISz/F2yZB756SOkHJ94AA06BvidSE5PK68vz2PSFm50lS9hZUkVeSTV1Xh+D0hK495sjuHhcJj0SY4L9bkRCksJYpKuqq4RVr8DnT0DxFmcO54k3waiLIHN849KAi7fu4943P2X7vkqSYiPp3yOe4b2SOGtkBlOG9mTSoFRMRy8jKBJmFMYiXU15ASx50mkJV++HPmPhkqdh5AUHnQfeX1nHr+es57XlefTvEc+L35vIKUPSgli4SPhSGIt0FQWr4LO/OfNA+zww/Dw46VbImgTGsL+yjtX5RazOL2NNfhmfbSumosbD/0w5jtumDSE2SnNBi7QXhbFIuKqvgZ2LnfPAWz+GvesgOhFO/B71OTfyeWkyX20rY/XCL1mdX0Z+aXXjU/v3iOe0IencPOU4RvTWrFgi7U1hLBJuqkpg3s9h1b/BUw2uaMg6Cb7xMIy5iiJPHLe89CVLcjcATvCOyerGNSf154TMFEZlppASF3WYFxGRtqQwFgkXPh+sfBE+esCZH3rs1TDsPBgwGaITAFi5q5QfvPBfSqvr+M0loznn+N4KXpFOQGEsEg72rIF374RdX0DWyXDe7yFj5EGbvLpsF/fNWkN6Ygxv3Hwyo/qkBKlYEWlKYSwSymrdMP9h+OLvENcNLnwCsmc0XpYEsK2ogt9/uIl3VxcweXAP/jxjHKkJ0cGrWUS+RmEsEoqsdWbJ+uAecO+B8dfBtPsh/sBCDHvKanh83mZeXbaLmMgI7jhzKLdMPY5IV0Tw6haRZimMRUKNuxDeugW2fAS9ToArXoS+OY0P76uo5cmF23hucS4+a7lmUn9uPWMwaZodS6TTUhiLhJJNH8Ksm6GuwhkdPeFGcDn/jRtC+IXPdlDr8XLhmEzuOGso/VI1T7RIZ6cwFgkFnlpnlPQXT0DPUXDpO9BzBADumnr+On8rzy3ObQzhW88YzKD0xCAXLSKt1aowNsacAzwOuICnrLWPNHm8P/AMkA6UAFdba/PauFaRrqe+Bta8Doseh32bYMJNcNYvICoWj9fHv5ft4g8fbqK4so4Lx/ThtmlDFMIiIeiwYWyMcQF/Bc4C8oClxpjZ1tp1AZs9CjxvrX3OGHMG8DBwTXsULNIlVO6DpU/D0n9CZZHTGr7qNRh6NgD/3byPX76zjo2FbiYMSOXZ745kdF9dqiQSqlrTMp4AbLHWbgMwxswELgACw3gkcKf/5/nArDasUaTrsBZWzYQ5P3bOCw85G066BQaeDsawZW8Fv56zno837KVfahxPfHsc5xzfS6smiYS41oRxJrAr4HYeMLHJNquAi3G6si8CkowxPay1xW1SpUhXUFMG79zpdEv3nwzn/xHShwHOCkqPz9vMi5/vIC7KxU/PHc51kwcQE6nFG0TCQVsN4Pox8BdjzHXAQiAf8DbdyBhzI3AjQFZWVhu9tEgY2LUE3vgelOXD1Pvg1DshwsXe8hqeXrSdlz7fSVWdh6smZnHHmUPpocuURMJKa8I4H+gXcLuv/75G1trdOC1jjDGJwCXW2tKmO7LWPgk8CZCTk2OPrmSRMFJTDvN/DUv+ASl94fr3od8Etu+r5B8LtvKfL/Px+Hycd0IffnjGYIZmJAW7YhFpB60J46XAEGPMQJwQvhK4KnADY0waUGKt9QE/xRlZLSItsRbW/gfevwcqCiHnejjzAWpciTz23gb++ek2IiMMl5/YlxtOHUT/HgnBrlhE2tFhw9ha6zHG3Ap8gHNp0zPW2rXGmF8Ay6y1s4EpwMPGGIvTTX1LO9YsEtqqSuD162HbfOg9Bma8DJnj+e/mfdw7ayE7iqu4bHxf7jpnOOlJ6o4W6QqMtcHpLc7JybHLli0LymuLBE1NGTw3HYo2wNm/gpzrySur5fcfbuLNFfkMTEvgoYuO5+Tj0oJdqYi0MWPMcmttTnOPaQYukY5SVwkvXwGFa+HKl8lLP4W/zlrHa8t2EWEMt04dzK1nDCY2SiOkRboahbFIR/DUwsxvw64vcJ//JL9e05vXln1ChDFcNTGLm6ccR++UuGBXKSJBojAWaW/11fDG92HbfFaN/zXXz+lGec0uhbCINFIYi7QXd6EzneXSp6G6hFfTb+OuRQMYnRnHy5dNYlgvXaYkIg6FsUhbqq+GHYtg9Ruw5nWst568jKk8WDuVhbsH85NvDOWm0wYR6YoIdqUi0okojEWOVVUJrHwZts6DHYvBU4ONSiB3wOXcV3AKi3Ykk9O/O+9cNFqtYRFplsJY5FgUb4UXL4H92yFtGHb8d1kbn8MDq1JYvraOYRlJPPWdYUwb0VOLOYhIixTGIkcrbzm8fJnz8/UfstIM47fvb2Dx1mIyu7n4w+XZXDAmE1eEQlhEDk1hLHI0Nr4Pr38XEnuy7RvP89sFHt5fu4geCdE88K2RXDUxSysqiUirKYxFjtSKF2H2D6lMPZ5743/GrGfzSIh2cfuZQ/j+qYNIjNF/KxE5MvqtIXIYJZV1fJVXSll1PT03/5uT1v6cldHjuCr/VmITDHeeNZTvnNSfbvHRwS5VREKUwljkEBZsKuL2mSvYX1XP5a75/Dbqn8z3ZvOQ627+b/owLs/pR1y0uqNF5NgojEWa4fVZHp+3mT9/vJmhPZN4dcIWhnz+T2oHTuPkK15gbqyWNBSRtqMwFmmiuKKW2/+9kk837+PSsb15uM9/iZr3Mxh8FjFXvAhRscEuUUTCjMJYxM9ayztfFfDzt9dRXlPPk9MiOGv7nZj1K2DYeXDpMwpiEWkXCmMRIG9/FT+btYb5G4uY1NvF34bOIXXRC5DYEy55Go6/BDRph4i0E4WxdGk19V6eW5zLY3M3Y4zl2fHbOT33Mcz6Yph4E0y9B2JTgl2miIQ5hbF0STX1Xl76Yid/X7CVInctVw+q5mfmKWLWfgaZ4+Hbr0OfMcEuU0S6CIWxdBker4/1BW4+3VLEvxblUuSu5ZRB3Zg1/GMy1/4DohPh/Mdg3LUQoVWVRKTjKIwlrJVV1/Pi5ztYvHUfK3aWUlXnBeCkQT34x4V9GbfkTli9CLJnwFm/hMT0IFcsIl2RwljCksfr4+UlO/njR5sora5nRK9kLhvfl/EDUsnp350+ZSvhtelQUw4XPQnZVwS7ZBHpwhTGEnY+2biXX727ni17K5g0KJX7zhvJ8Zn+QVjWwhd/hw/vg25ZcPV/oNfxwS1YRLo8hbGEjfKaeh54ay1vrshnQI94/nHNeM4emXFgHWGfF977P1j6T+e64Yue0EhpEekUFMYSFr7YVsydr65iT3kNt00bwq1TBxMdGTAIq74a3vg+bHgHTrrVOT+sQVoi0kkojCWkVdV5eHzeZp5cuI3+qfG89oOTGJfVvclGJfDKlbBrCZzzCEy6OTjFioi0QGEsIamkso5nF+fy/Ge5lFbVM2NCFvedN4KEwLWEvfWw7i2Y/xCU5cNlz8KoC4NVsohIixTGElKKK2r588dbmLl0JzX1Ps4ckcHNU45jfP+A1nD1flj+HCx5Esrzocdg+M4s6H9y0OoWETkUhbGEjOU7SrjlpRXsq6jlwrGZ3HTaIIZkJB280YY58J8boc4NA0+D8/8Ig8/S+WER6dQUxtLpWWt5ZlEuD89ZT59uccy6ZfKBS5UCLX0a5vwYeo+Bbz0OvU/o8FpFRI6Gwlg6tSJ3Lfe/tYb31uzhrJEZPHpZNilxUQdvZC18/Ev49Pcw9BxnqcPohOAULCJyFBTG0ukUuWt5f+0e5nxVwBfbizHGcM83h3PDqYMOXDPcwFMLb/8IVr3izCl93h/ApY+1iIQW/daSTqO0qo5fvLOOWSvy8VkYlJ7ALVMHc8GYPgzumfT1J+R/CW/dAnvXwdR74bSfaM1hEQlJCmPpFD5aV8g9b65mf2Ud108eyKU5fRmWkfT1ljA4reEFv4H/PgaJPeGqV2HoNzq8ZhGRtqIwlqDaX1nHz99ey6yVuxnRO5l/XXdi84OzGuQtg9k/dFrDY74N3/g1xHXrsHpFRNqDwliCorrOy7OLc3niky1U1Xm5/cwh/M+UJlNYBqoqgXk/d64fTuoNV70GQ8/u2KJFRNqJwlg6VL3Xx2vL8nh83iYKy2s5Y3hP7jpnGMN7JTf/BJ8PVr0MH90P1aVw0i0w5W6IaeYcsohIiFIYS4f57+Z9PDB7DVuLKhnfvzt/njGOCQNTm9/YWtg4Bz55BPZ8Bf0mwfl/gIxRHVu0iEgHUBhLuysoq+ZX76zn3dUF9O8Rz5PXjOeswKUNA1kLG96FBY/AntWQOggu+geMvlyzaIlI2FIYS7upqffyzKLt/OXjLXh9ljvPGsqNpw0iNsrV/BMKvoJ374S8pU4IX/h3GH2ZrhsWkbCn33LS5qy1zFm9h0feX8+ukmrOGpnB/eePpF9qfPNPqCmH+b+GJf+AuFSY/hfInqEQFpEuQ7/tpE19lVfKL99Zx9Lc/QzvlcSL35vIKUPSmt/Y54M1b8CH90FFIeRcD9N+BnHdm99eRCRMKYylTWwrquD3H23i3a8KSEuM5uGLR3N5Tj9cES3MiJW7yAnh3V86CzvMeBkyx3dozSIinYXCWI7JnrIaHp+3mVeX7SImMoLbpg3hhlMHkhQb1fwTirc6lylteAeSMzU4S0QEhbEcAWstq/LKWLFzP6vzy1iTX8aWvRW4IgzXTOrPrWcMJi0xpvkn+7zw2V/g44fAFQVn/Awm/Q9Et3AeWUSkC1EYS6uUVtVx76w1vPtVAQDpSTGMzkzh3ON7c8m4vmT1OESoFm2CWTdD/jIYfr6zslJSRgdVLiLS+SmM5bD+u3kfP35tFfsqavnfs4ZyWU4/MpJjmr9OOFB1KSz5Jyz8nbO+8CVPw/GXaGUlEZEmFMbSopp6L799fyPPLNrOcekJ/PM7kxnd9xCLODQo2QZf/AO+fAHqK2HEdDjv984KSyIi8jUKY2nW2t1l3D5zJZv3VvCdk/rz03NHEBfdwmQdDQpWOa3g9e9ARCSMvtQ5L9z7hI4pWkQkRCmM5SBen+XJhdv4w0cb6R4fzbPfPZEpww7Toi1YBQt+64yQjk2BU++ECTdCUq+OKVpEJMQpjAWAyloPX2wv5u8LtrFkewnnHt+LX180mu4J0c0/wVrY+Tks/jNsfNcJ4an3wsSbnJ9FRKTVFMZdWGF5DTOX7GLRln18uXM/Hp8lKSaS31+WzcXjMpsfoOWth3VvwWd/dSbsiOuuEBYROUYK4y5qyfYS/uel5RRX1nF8nxRuOG0QpwxOY3z/7i0v5LB5Lrz9IyjPgx6DnUuUsmfoWmERkWOkMO5irLW8+PkOfv72OvqlxvPyDZMYmpF06Cd5amHuz+Hzv0L6CJjxbxhytmbNEhFpIwrjLqSm3svPZq3hteV5TB2WzmNXjiUlroVpKxvs2wyvXw97voITb4CzfwlRcR1TsIhIF6Ew7gKstcxbv5dfz1nPtn2V3HbGYG4/cygRLS3iAFC6C774Oyx7BiJj4cpXYPg3O65oEZEuRGEc5tYXlPOrd9exaEsxg9ITeO76CZw+NL3lJ+Qtd+aQXveWc3vUhXD2ryC5T4fUKyLSFSmMw9TqvDKeWbSdt1bmkxwXxc+nj+KqiVlEuZo5z1tdCqtfgxUvONcMx6TASbc41wp369fhtYuIdDUK4zDi8fp4f+0enl2Uy7Id+0mIdvG9UwZy69QhpMQ3c2549wr4/AmnFeypgV6j4ZuPQvaVEHOYQV0iItJmFMZhYm95Ddf+aynrC8rJSo3nZ+eP5LKcviQ3t65w/pew4Dew6X2ISYYx34Zx34E+Yzq8bhERaWUYG2POAR4HXMBT1tpHmjyeBTwHdPNvc7e1dk7bliot2VVSxdVPf0GRu5Y/zxjLN0f3xtXc4KyCVTD/104Ix3V31hSecCPEJnd80SIi0uiwYWyMcQF/Bc4C8oClxpjZ1tp1AZvdB7xqrX3CGDMSmAMMaId6pYlNhW6uefoLaup9vPj9iYzL6v71jcry4ONfwaqZENdNISwi0sm0pmU8Adhird0GYIyZCVwABIaxBRp+s6cAu9uySGneql2lXPuvJUS5Ivj3TZMY3qtJuNaUw6LHnKkrrYXJP3IWcdC0lSIinUprwjgT2BVwOw+Y2GSbB4EPjTE/BBKAM9ukOmnR26t2c9frX5GWFM2L35tI/x4JB29QtBFevgL2b4fRl8O0n0G3rOAUKyIih9RWA7hmAM9aa39vjDkJeMEYc7y11he4kTHmRuBGgKwsBcPR8Hh9/O6Djfxj4TZy+nfnb1ePo2dS7MEbbZ4Lr38XImPgu+9B/5ODU6yIiLRKa8I4Hwi82LSv/75A3wPOAbDWfmaMiQXSgL2BG1lrnwSeBMjJybFHWXOXtb+yjh++soL/btnH1ZOyuP/8UURHBlw3bK1zqdKH90LPUTDjFV0nLCISAloTxkuBIcaYgTghfCVwVZNtdgLTgGeNMSOAWKCoLQvt6ipqPVz8xGLy91fzm0tGc8WJTXoW9qyGT38Pa9+E4efDRf+AmMTgFCsiIkfksGFsrfUYY24FPsC5bOkZa+1aY8wvgGXW2tnA/wL/NMbcgTOY6zprrVq+beixjzaxfV8lL39/IicPTnPu9Plgy0fOAK3tCyAqHqb8FE67SysqiYiEkFadM/ZfMzynyX33B/y8DpjctqVJg/UF5fxrcS4zJvQ7EMQVe+Hly51ZtJL6wJkPwrhrIT41qLWKiMiR0wxcnZzPZ7lv1hpS4qL4v3OGO3eW7oLnLwB3AVz4BIy+DFyHWQpRREQ6LYVxJ/fa8l0s37Gf3116At3io6F4Kzw3HWrdcM0syGp6lZmIiIQahXEnVlJZx8PvbWDCgFQuHd8X9qyBFy4C64Pr3obe2cEuUURE2oBG+XRij7y3nooaD7+88HjMpvfhX990uqO/+56CWEQkjCiMO6lXl+3i1WV5fH9yFsPWPgavXAmpA+D69yF9aLDLExGRNqRu6k5ozuoC7n7jK745KJK79t3jXLY09hpnreGo2MPvQEREQorCuJNZsKmIH81cwbRMD3+puIuIwiKY/mdnvWEREQlLCuNOZGluCTe9sIzj06N4IvIRIsrL4Pr3IHN8sEsTEZF2pHPGnUTe/iquf3YpfZJjmdnrJSL3fAWX/FNBLCLSBSiMO4k/z9tCrcfHf074gpgNb8K0+2HYucEuS0REOoC6qTuBHcWVvP5lHr8cvotunz0Cx18Kp9wR7LJERKSDqGXcCTw+bzMDIwq5Mu8XzvXD0/8MxgS7LBER6SBqGQfZ1qIKZq3IY17aC0TURcAVL0J0fLDLEhGRDqQwDrI/zdvMVVELGeheDuf/Ebr1C3ZJIiLSwRTGQbS50M1nq9ayMP4l6DsZxl0X7JJERCQIdM44iB6bu5mHop8jhnr41p8gQv8cIiJdkX77B8ma/DI8a9/iLLMEM+X/IG1wsEsSEZEgUTd1EHi8Ph56YzF/jn4Wb8/RuE6+LdgliYhIEKllHATPLtrOtUW/J9VU4Lrwz86yiCIi0mUpjDvYrpIqCuf+iXNcSzFnPgB9xga7JBERCTKFcQey1vLPma9zl3mBmkFnY07+YbBLEhGRTkBh3IHeXbqeG/b8gtq4nsRe+g/NsiUiIoAGcHWYYncNcXN+RO+IEsxV70N8arBLEhGRTkIt4w6y/M0/Mo0llJx8L66sCcEuR0REOhGFcQfw7N/FydseZ13sWHqedWewyxERkU5GYdzerKXk1R8SYX0UT/2dzhOLiMjXKIzb29r/0LNgPk+6ruSknPHBrkZERDohDeBqT1UleN/9CWt9g/BOuolIl/72ERGRr1M6tKcP7oWaUu6qv5HLJwwMdjUiItJJKYzby7YFsOplXoi4iPTB4+iXGh/sikREpJNSGLeXpU9RG5vOw5Xnc+WJWcGuRkREOjGFcXuoq4TNH7E4+mQSExI5a2RGsCsSEZFOTGHcHjZ/BJ5qnio+gUvG9yU6UodZRERappRoD+veojqqO595h3HFif2CXY2IiHRyCuO2Vl8Nmz5goWsSx/ftznHpicGuSEREOjmFcVvbMg/qK3m+fAxn61yxiIi0gsK4ra17i5qobnzhG8HZo3oFuxoREQkBCuO25KmFTe/zRfQk+vZIZkhPdVGLiMjhKYzb0rZPoLac58qyOXtUL4wWhRARkVZQGLeldW9RF5XMp55ROl8sIiKtpoUi2oqnDja8w4q4SaTYeMZmdQ92RSIiEiIUxm0ldyHUlPF89RjOPCEDV4S6qEVEpHXUTd1WVr+OJzKBubUj+YZGUYuIyBFQGLeFiiJY8wZLU75BZHQcJx3XI9gViYhICFEYt4UvnwVvHb8vO50pw3oSG+UKdkUiIhJCFMbHylsPS5+mLPM0llWkc/YojaIWEZEjozA+Vutng7uADxIvJDLCMGVYz2BXJCIiIUajqY/VF//Apg7iT7n9mTw4mZS4qGBXJCIiIUYt42OR/yXs+oK8wVeTV1bL9Ow+wa5IRERCkML4WCx5EqITebH2FKIjI3S+WEREjorC+GhV7IU1b+DLnsF/1rk5Y1hPkmLVRS0iIkdOYXy0lj8L3jpW9rqcInct31IXtYiIHCWF8dFaOwv6n8JrO2JJiHZxxnCNohYRkaOjMD4a7kLYuxbPoDN4b80ezhqZQVy0JvoQEZGjozA+GtsXALAiagylVfXqohYRkWOiMD4aW+dDXCqv7OxOSlwUpw5JD3ZFIiISwhTGR8pa2DYfz4DT+GDdXs49vhfRkTqMIiJy9JQiR6poI7gLWBc3nso6r7qoRUTkmGk6zCO1bT4Ar+8fTFpiNJMGablEERE5Nq1qGRtjzjHGbDTGbDHG3N3M4380xqz0f20yxpS2eaWdxdb52NRBzNkVxWlD0nBFmGBXJCIiIe6wLWNjjAv4K3AWkAcsNcbMttaua9jGWntHwPY/BMa2Q63B56mD3P9SPuwS9u2uY8LA1GBXJCIiYaA1LeMJwBZr7TZrbR0wE7jgENvPAF5pi+I6nfxlUF/JV9HjABTGIiLSJloTxpnAroDbef77vsYY0x8YCHx87KV1Qlvng4lgTsVg0hJjGJiWEOyKREQkDLT1aOorgdettd7mHjTG3GiMWWaMWVZUVNTGL90Bts2HzPEs3FnPxIGpGKPzxSIicuxaE8b5QL+A23399zXnSg7RRW2tfdJam2OtzUlPD7GJMqpLIX855X1OIb+0Wl3UIiLSZloTxkuBIcaYgcaYaJzAnd10I2PMcKA78FnblthJ5H4K1seKqDGAzheLiEjbOWwYW2s9wK3AB8B64FVr7VpjzC+MMdMDNr0SmGmtte1TapBtnQ9RCXxY2o/k2EiGZSQFuyIREQkTrZr0w1o7B5jT5L77m9x+sO3K6oR2LIL+J/PZDjcTBqYSoeuLRUSkjWg6zNaoq4R9m6hMz2bbvkp1UYuISJtSGLfGnjVgfayzgwCYMFBTYIqISNtRGLdGwUoAFrj7EB/tYlSf5ODWIyIiYUVh3Bq7V0JCT+bmRTC+f3eiXDpsIiLSdpQqrVGwkvqME9hQWMGEATpfLCIibUthfDh1VVC0gV0xQwFdXywiIm1PYXw4hWvB+lhen0W0K4Lsft2CXZGIiIQZhfHh+AdvfVDSm+x+KcRGuYJbj4iIhB2F8eEUrMTG92BRUQyjM7sFuxoREQlDCuPD2b2K6rTRVNf7GN5bU2CKiEjbUxgfSn0NFK1nd9wwAEb00vXFIiLS9hTGh7J3Lfg8rDODiDAwJCMx2BWJiEgYUhgfyu6VAHxW2ZeBaQkavCUiIu1CYXwoBSshrjuL9sUzvLe6qEVEpH0ojA+lYBWejGx27q9mRC8N3hIRkfahMG6JpxYK11GUNAKA4Rq8JSIi7URh3JK968BXzxbXcQC6rElERNpNZLAL6LQKVgGwtDaLpBjI7BYX5IJERCRcKYxbsnslxKbwWUkiw3sbjDHBrkhERMKUuqlbUrAS2zubDXsqdL5YRETalcK4OTVlUPAV7rSxuGs9Ol8sIiLtSmHcnG0LwHrZmDgR0EhqERFpXwrj5mz5CGJSWOIZBMAwXWMsIiLtSGHclLWwZR4MOp11hdVkpcaTGKNxbiIi0n4Uxk0VbYDyfBh8JhsKyhmuVrGIiLQzhXFTW+YCUDNgCtv3VWpOahERaXcK46a2zIX0EWyu7obPojmpRUSk3SmMA9VVwo7FMHga6/eUA6hlLCIi7U5hHCj3v+CtgyFnsaHATVyUi6zU+GBXJSIiYU5hHGjLXIiKh6yT2LCnnKG9knBFaBpMERFpXwrjQJs/goGnYV3RbNjjZniGzheLiEj7Uxg3KN4K+7fD4DMpctdSUlmnaTBFRKRDKIwbbJnnfB88jQ173IBm3hIRkY6hMG6wZS6kDoLUQWz0h7HmpBYRkY6gMAbw1EHup3DcNAA27HGTnhRDakJ0kAsTEZGuQGEMsOcrqK+CgacCsLFQ02CKiEjHURgD7PzM+d5vEl6fZXNhBcM0klpERDqIwhhg5+fQfSAkZZBbXEmtx6fBWyIi0mEUxtY6LeOskwA0eEtERDqcwrh4C1QVQ9YkwBm8FWFgSEZikAsTEZGuQmHccL64sWVczoAeCcRGuYJYlIiIdCUK452fQ1wqpA0BnG5qnS8WEZGOpDBuOF9sDFV1HnaUVCmMRUSkQ3XtMHYXQsm2xvPFmwsrsBZdYywiIh2qa4fxrs+d701GUg/TSGoREelAXTuMd34OkbHQOxtwRlLHRkWQlRof5MJERKQrURhn5kCkMwf1xsJyhmYk4YowQS5MRES6kq4bxnWVULCq8Xwx+EdSaxpMERHpYF03jPOWgfU2ni/eV1HLvoo6jaQWEZEO13XDeOfngIF+JwKaBlNERIKnC4fxZ5AxCmJTAGfwFqCWsYiIdLiuGcZeD+QtbXK+uJweCdGkJ8UEsTAREemKumYYF6yCuorG88WgaTBFRCR4umYYb//E+T7wdAB8PsumwgqFsYiIBEXXDONtC6DnKEhMB2BHSRXV9V5GaPCWiIgEQdcL4/oa2PUFDDq98a4NBeUADO+tlrGIiHS8rhfGeUvAU9PYRQ2wvqCcCANDNeGHiIgEQdcL420LwLig/8mNd60rcDMoPZHYKFcQCxMRka6q64Xx9gWQOQ5iD5wf3rCnXMsmiohI0HStMK4ph/wvD+qiLq+pJ29/NSN6a/CWiIgER6vC2BhzjjFmozFmizHm7ha2udwYs84Ys9YY83LbltlGdixy5qMOGLzVMA3mSIWxiIgESeThNjDGuIC/AmcBecBSY8xsa+26gG2GAD8FJltr9xtjerZXwcdk+0Jn/eK+ExrvWq+R1CIiEmStaRlPALZYa7dZa+uAmcAFTba5AfirtXY/gLV2b9uW2Ua2LXCmwIyKbbxrfUE53eKj6JUce4gnioiItJ/WhHEmsCvgdp7/vkBDgaHGmEXGmM+NMec0tyNjzI3GmGXGmGVFRUVHV/HRqiiCvWsPOl8MsL7AzfBeSRhjOrYeERERv7YawBUJDAGmADOAfxpjujXdyFr7pLU2x1qbk56e3kYv3UrbFzjfA8LY67Ns3OPW4C0REQmq1oRxPtAv4HZf/32B8oDZ1tp6a+12YBNOOHce2xdATAr0GdN4147iSmcaTIWxiIgEUWvCeCkwxBgz0BgTDVwJzG6yzSycVjHGmDScbuttbVdmG9i+EAacAhEHJvZoWMNYc1KLiEgwHTaMrbUe4FbgA2A98Kq1dq0x5hfGmOn+zT4Aio0x64D5wE+stcXtVfQRK90F+3MPuqQJDkyDOSQjMTh1iYiI0IpLmwCstXOAOU3uuz/gZwvc6f/qfEr8jfSeIw66e72mwRQRkU6ga8zAVVHofE/sddDd6wvKdb5YRESCrmuEsXuP8z0po/Gusup68kurGaHJPkREJMi6RhhXFEJkHMQcaAVv1OAtERHpJLpOGCdlQMDEHg3TYKqbWkREgq1rhLF7DyRmHHTXhj3ONJgZyTFBKkpERMTRNcK4ovBrYbyuwM2IXsmaBlNERIKua4SxuxCSDoykdqbB1EhqERHpHMI/jOurobbsoJbx9n2V1NT7NJJaREQ6hfAP44ZrjANaxqvzSwE4oW+3jq9HRESkifAPY3fDhB8HWsar88qJjYrguPSEIBUlIiJyQPiHcYV/wo/AMM4vZVSfFCJd4f/2RUSk8wv/NHIf3E3t9VnW7i5ndGZKEIsSERE5IPzDuKIQjAviewCwraiCqjqvwlhERDqNLhDGeyAhvXEd46/yygAY3VdhLCIinUP4h7G78KAFIlbnlxEX5eK4dK1hLCIinUP4h3HFnoOWTlydX8bxmcm4IjTzloiIdA7hH8YBLWOP18e63eUcr/PFIiLSiYR3GPu8ULWvsWW8taiS6novJ+h8sYiIdCLhHcaVRWB9kNgTgK/ySgE0klpERDqV8A5jt3/CD/81xmvyy0iIdjEwTYO3RESk8wjvMG6Yl9rfTf1VfhmjMlM0eEtERDqV8A7jxpZxRuPgLXVRi4hIZxPeYVyx1/memMHmvRXUenwavCUiIp1OmIfxHojtBpExrPbPvKXLmkREpLMJ7zB272kcvLU6v4zEmEgG9tCyiSIi0rmEdxhXFDYunfhVfhmj+iQTocFbIiLSyYR/GCf1ot7rY31Buc4Xi4hIpxS+YWytMxVmYgZbiyqo8/h0vlhERDql8A3jmlLw1kJiBrn7KgG0UpOIiHRK4RvGbv+EH0m92FlSBUC/1PggFiQiItK88A3jCv+EH4kZ7Ciuolt8FClxUcGtSUREpBlhHMb+CT/8LeMstYpFRKSTCt8wdh9oGSuMRUSkMwvfMK4ohMg4PJEJ5O+vVhiLiEinFb5h7N4DSRkUlNfi8Vn691AYi4hI5xS+YVxRCIkaSS0iIp1feIdxUkZjGPfXnNQiItJJhW8Y+2ff2lFcRZTL0Cs5NtgViYiINCs8w7i+GmrLIDGDXSVV9Osej0sLRIiISCcVnmHccFlTUi92lFTqfLGIiHRq4RnGDRN+JPZiZ3GVRlKLiEinFp5hXFUMgNuVQnmNR9cYi4hIpxaeYVzrBiC/OhJAYSwiIp1amIZxOQA7KlwAZKmbWkREOrHwDOO6CgBy3c4IarWMRUSkMwvPMK51g3Gxbb+PtMQY4qMjg12RiIhIi8I3jGOS2Lm/WiOpRUSk0wvTMK5wwlhLJ4qISAgI0zAuxxedyO4yLZ0oIiKdX5iGsZs6VwLWavCWiIh0fuEZxnUVVBEHoHPGIiLS6YVnGNe6KbdOGKtlLCIinV3YhvF+bwyxURGkJ8UEuxoREZFDCs8LcGsrKDbRZKXGY4yWThQRkc4t/FrGPh/UudlTG0VWakKwqxERETms8Atj/1SYu6sjdb5YRERCQtiG8X5vjEZSi4hISAi/MPYvn1hh49QyFhGRkBCGYey0jN3EaSS1iIiEhFaFsTHmHGPMRmPMFmPM3c08fp0xpsgYs9L/9f22L7WV/GsZV9o4EmPCc7C4iIiEl8OmlTHGBfwVOAvIA5YaY2Zba9c12fTf1tpb26HGI9PQTU0c8TGuIBcjIiJyeK1pGU8Atlhrt1lr64CZwAXtW9YxqDvQTa2WsYiIhILWhHEmsCvgdp7/vqYuMcZ8ZYx53RjTr02qOxr+lnEVscRGqmUsIiKdX1sN4HobGGCtPQH4CHiuuY2MMTcaY5YZY5YVFRW10Us34T9n7ItKJCJCs2+JiEjn15owzgcCW7p9/fc1stYWW2tr/TefAsY3tyNr7ZPW2hxrbU56evrR1Ht4tRXUm2iiY+LaZ/8iIiJtrDVhvBQYYowZaIyJBq4EZgduYIzpHXBzOrC+7Uo8QrVuaiPiSND5YhERCRGHTSxrrccYcyvwAeACnrHWrjXG/AJYZq2dDdxmjJkOeIAS4Lp2rPnQat1UmXjio3W+WEREQkOrmo/W2jnAnCb33R/w80+Bn7ZtaUeproJK4tUyFhGRkBGGM3C5qSKWBLWMRUQkRIRhGJfjtnHEq2UsIiIhIgzDuIIyG0ditMJYRERCQxiGsZtyX4ymwhQRkZARdmFsa92UemNJUMtYRERCRHiFsdeD8VRT7ovVaGoREQkZ4RXGdc681JXEkaBuahERCRHhFcb+RSLcxBGvbmoREQkRYRbGzvKJFTaORLWMRUQkRIRZGDd0U8eqZSwiIiEjLMO4wuqcsYiIhI7wCuO6hnPGmptaRERCR3iFcUM3tdV1xiIiEjrCLIz9A7iI0xKKIiISMsIsjP3njIlTN7WIiISMMAvjcuojYjERLmIiw+utiYhI+AqvxKqroCYigfhoF8aYYFcjIiLSKuEVxrVuaiLiSFQXtYiIhJCwC+MqE6/BWyIiElLCLIwrqNI1xiIiEmLCLIzdVKBrjEVEJLSEWRiX49ZUmCIiEmLCK4zrKii3WiRCRERCS3ilVq2bMhujc8YiIhJSwie1PLXgrWO/L5YEjaYWEZEQEj7d1P55qUu8McSrZSwiIiEkjMK4HIBKG0eiBnCJiEgICaMwPrBIhAZwiYhIKAmfMK5zuqnd6NImEREJLeETxv6WcaXVpB8iIhJawi6MtZaxiIiEmrALY7fVQhEiIhJawi6MK4nVEooiIhJSwiqMLYYqdJ2xiIiElvAJ47oK6l0JWCI0A5eIiISU8Anj2nLqXPEAus5YRERCShiFcQU1rniiXRFER4bP2xIRkfAXPqlV66baxBOvCT9ERCTEhF0Ya8IPEREJNeETxnUVVGoqTBERCUHhE8a1btxWs2+JiEjoCaMwLsetealFRCQEhUcYWwu1FZT7YjUVpoiIhJzwCOP6arBeSn2aClNEREJPeISxf17qUk+MLm0SEZGQEx5hXFcBQLE3RueMRUQk5IRHGNeWA7DfE6PR1CIiEnLCJIwblk+M0wAuEREJOWESxk43ta4zFhGRUBQmYey0jCtQGIuISOgJjzCOTaGy53jKbbzWMhYRkZATHmE87By++sZr7CdZaxmLiEjICY8wBiprPQCa9ENEREJO+IRxnRPGmvRDRERCTdiEcVWdF0CTfoiISMgJmzBu6KbWesYiIhJqwiiMnZaxBnCJiEioCZvkqqrzEBsVgSvCBLsUEelC6uvrycvLo6amJtilSCcRGxtL3759iYqKavVzwiaMK2o9GkktIh0uLy+PpKQkBgwYgDFqDHR11lqKi4vJy8tj4MCBrX5eq7qpjTHnGGM2GmO2GGPuPsR2lxhjrDEmp9UVtJGqOq+6qEWkw9XU1NCjRw8FsQBgjKFHjx5H3FNy2DA2xriAvwLnAiOBGcaYkc1slwT8CPjiiCpoI5W1Hi0SISJBoSCWQEfzeWhNy3gCsMVau81aWwfMBC5oZrtfAr8BgnLipLJO3dQi0vUUFxczZswYxowZQ69evcjMzGy8XVdXd8jnLlu2jNtuu+2wr3HyySe3VbkA3H777WRmZuLz+dp0v6GsNemVCewKuJ0HTAzcwBgzDuhnrX3XGPOTNqyv1SprvSTHtf5kuYhIOOjRowcrV64E4MEHHyQxMZEf//jHjY97PB4iI5v/VZ+Tk0NOzuHPKi5evLhNagXw+Xy8+eab9OvXjwULFjB16tQ223egQ73vzuiYL20yxkQAfwD+txXb3miMWWaMWVZUVHSsL32QylqPFokQEQGuu+46fvCDHzBx4kTuuusulixZwkknncTYsWM5+eST2bhxIwCffPIJ559/PuAE+fXXX8+UKVMYNGgQf/rTnxr3l5iY2Lj9lClTuPTSSxk+fDjf/va3sdYCMGfOHIYPH8748eO57bbbGvfb1CeffMKoUaO4+eabeeWVVxrvLyws5KKLLiI7O5vs7OzGPwCef/55TjjhBLKzs7nmmmsa39/rr7/ebH2nnnoq06dPZ+RI52zqhRdeyPjx4xk1ahRPPvlk43Pef/99xo0bR3Z2NtOmTcPn8zFkyBAassnn8zF48GDaOqta0po/G/KBfgG3+/rva5AEHA984u8n7wXMNsZMt9YuC9yRtfZJ4EmAnJwcewx1f01VnVfLJ4pIUP387bWs213epvsc2SeZB7416oifl5eXx+LFi3G5XJSXl/Ppp58SGRnJ3Llzueeee3jjjTe+9pwNGzYwf/583G43w4YN4+abb/7a5TkrVqxg7dq19OnTh8mTJ7No0SJycnK46aabWLhwIQMHDmTGjBkt1vXKK68wY8YMLrjgAu655x7q6+uJioritttu4/TTT+fNN9/E6/VSUVHB2rVr+dWvfsXixYtJS0ujpKTksO/7yy+/ZM2aNY0jmZ955hlSU1Oprq7mxBNP5JJLLsHn83HDDTc01ltSUkJERARXX301L730Erfffjtz584lOzub9PT0IzzyR6c1LeOlwBBjzEBjTDRwJTC74UFrbZm1Ns1aO8BaOwD4HPhaELe3yjq1jEVEGlx22WW4XM7vxLKyMi677DKOP/547rjjDtauXdvsc8477zxiYmJIS0ujZ8+eFBYWfm2bCRMm0LdvXyIiIhgzZgy5ubls2LCBQYMGNQZgS2FcV1fHnDlzuPDCC0lOTmbixIl88MEHAHz88cfcfPPNALhcLlJSUvj444+57LLLSEtLAyA1NfWw73vChAkHXVL0pz/9iezsbCZNmsSuXbvYvHkzn3/+Oaeddlrjdg37vf7663n++ecBJ8S/+93vHvb12sphm5LWWo8x5lbgA8AFPGOtXWuM+QWwzFo7+9B76BiVtR7i1TIWkSA6mhZse0lISGj8+Wc/+xlTp07lzTffJDc3lylTpjT7nJiYmMafXS4XHo/nqLZpyQcffEBpaSmjR48GoKqqiri4uBa7tFsSGRnZOPjL5/MdNFAt8H1/8sknzJ07l88++4z4+HimTJlyyEuO+vXrR0ZGBh9//DFLlizhpZdeOqK6jkWrzhlba+dYa4daa4+z1j7kv+/+5oLYWjulo1vFdR4f9V6r0dQiIs0oKysjMzMTgGeffbbN9z9s2DC2bdtGbm4uAP/+97+b3e6VV17hqaeeIjc3l9zcXLZv385HH31EVVUV06ZN44knngDA6/VSVlbGGWecwWuvvUZxcTFAYzf1gAEDWL58OQCzZ8+mvr6+2dcrKyuje/fuxMfHs2HDBj7//HMAJk2axMKFC9m+fftB+wX4/ve/z9VXX31Qz0JHCIu5qasalk9UN7WIyNfcdddd/PSnP2Xs2LFH1JJtrbi4OP72t79xzjnnMH78eJKSkkhJSTlom6qqKt5//33OO++8xvsSEhI45ZRTePvtt3n88ceZP38+o0ePZvz48axbt45Ro0Zx7733cvrpp5Odnc2dd94JwA033MCCBQvIzs7ms88+O6g1HOicc87B4/EwYsQI7r77biZNmgRAeno6Tz75JBdffDHZ2dlcccUVjc+ZPn06FRUVHdpFDWAaRsJ1tJycHLtsWds0oPP2V3HKb+bz20tO4PIT+x3+CSIibWT9+vWMGDEi2GUEXUVFBYmJiVhrueWWWxgyZAh33HFHsMs6YsuWLeOOO+7g008/Pab9NPe5MMYst9Y2ey1ZmLSM/WsZq5taRCQo/vnPfzJmzBhGjRpFWVkZN910U7BLOmKPPPIIl1xyCQ8//HCHv3ZYpFfDWsbxWstYRCQo7rjjjpBsCQe6++67ufvuFpdfaFdh0TJuWMs4QQtFiIhICAqPMPYP4EpQy1hEREJQWIRxw2hqtYxFRCQUhUUYJ8ZEkd03haRYhbGIiISesAjjs0Zm8Natp9AjMebwG4uIhJGpU6c2TinZ4LHHHmucWrI5U6ZMoeHS0m9+85uUlpZ+bZsHH3yQRx999JCvPWvWLNatW9d4+/7772fu3LlHUP2hdaWlFsMijEVEuqoZM2Ywc+bMg+6bOXPmIRdrCDRnzhy6det2VK/dNIx/8YtfcOaZZx7VvppqutRie2mPSVCOhsJYRCSEXXrppbz77ruN8zPn5uaye/duTj31VG6++WZycnIYNWoUDzzwQLPPHzBgAPv27QPgoYceYujQoZxyyimNyyyCcw3xiSeeSHZ2NpdccglVVVUsXryY2bNn85Of/IQxY8awdevWg5Y2nDdvHmPHjmX06NFcf/311NbWNr7eAw88wLhx4xg9ejQbNmxotq6uttSiTrKKiLSV9+6GPavbdp+9RsO5j7T4cGpqKhMmTOC9997jggsuYObMmVx++eUYY3jooYdITU3F6/Uybdo0vvrqK0444YRm97N8+XJmzpzJypUr8Xg8jBs3jvHjxwNw8cUXc8MNNwBw33338fTTT/PDH/6Q6dOnc/7553PppZcetK+amhquu+465s2bx9ChQ/nOd77DE088we233w5AWloaX375JX/729949NFHeeqpp75WT1dbalEtYxGREBfYVR3YRf3qq68ybtw4xo4dy9q1aw/qUm7q008/5aKLLiI+Pp7k5GSmT5/e+NiaNWs49dRTGT16NC+99FKLSzA22LhxIwMHDmTo0KEAXHvttSxcuLDx8YsvvhiA8ePHNy4uEagrLrWolrGISFs5RAu2PV1wwQXccccdfPnll1RVVTF+/Hi2b9/Oo48+ytKlS+nevTvXXXfdIZcPPJTrrruOWbNmkZ2dzbPPPssnn3xyTPU2LMPY0hKMXXGpRbWMRURCXGJiIlOnTuX6669vbBWXl5eTkJBASkoKhYWFvPfee4fcx2mnncasWbOorq7G7Xbz9ttvNz7mdrvp3bs39fX1BwVPUlISbrf7a/saNmwYubm5bNmyBYAXXniB008/vdXvpysutagwFhEJAzNmzGDVqlWNYZydnc3YsWMZPnw4V111FZMnTz7k88eNG8cVV1xBdnY25557LieeeGLjY7/85S+ZOHEikydPZvjw4Y33X3nllfzud79j7NixbN26tfH+2NhY/vWvf3HZZZcxevRoIiIi+MEPftCq99FVl1oMiyUURUSCRUsodk2HW2rxSJdQ1DljERGRI/DII4/wxBNPtMm54gbqphYRETkCd999Nzt27OCUU05ps30qjEVERIJMYSwicoyCNfZGOqej+TwojEVEjkFsbCzFxcUKZAGcIC4uLiY2NvaInqcBXCIix6Bv377k5eUd89zEEj5iY2Pp27fvET1HYSwicgyioqIOmlZR5Giom1pERCTIFMYiIiJBpjAWEREJsqBNh2mMKQJ2tOEu04B9bbi/rkrHsW3oOLYNHce2oePYNo71OPa31ja78HHQwritGWOWtTTnp7SejmPb0HFsGzqObUPHsW2053FUN7WIiEiQKYxFRESCLJzC+MlgFxAmdBzbho5j29BxbBs6jm2j3Y5j2JwzFhERCVXh1DIWEREJSWERxsaYc4wxG40xW4wxdwe7nlBhjOlnjJlvjFlnjFlrjPmR//5UY8xHxpjN/u/dg11rKDDGuIwxK4wx7/hvDzTGfOH/XP7bGBMd7Bo7O2NMN2PM68aYDcaY9caYk/R5PHLGmDv8/6fXGGNeMcbE6vN4eMaYZ4wxe40xawLua/bzZxx/8h/Pr4wx447ltUM+jI0xLuCvwLnASGCGMWZkcKsKGR7gf621I4FJwC3+Y3c3MM9aOwSY578th/cjYH3A7d8Af7TWDgb2A98LSlWh5XHgfWvtcCAb53jq83gEjDGZwG1AjrX2eMAFXIk+j63xLHBOk/ta+vydCwzxf90IPHEsLxzyYQxMALZYa7dZa+uAmcAFQa4pJFhrC6y1X/p/duP84svEOX7P+Td7DrgwKAWGEGNMX+A84Cn/bQOcAbzu30TH8TCMMSnAacDTANbaOmttKfo8Ho1IIM4YEwnEAwXo83hY1tqFQEmTu1v6/F0APG8dnwPdjDG9j/a1wyGMM4FdAbfz/PfJETDGDADGAl8AGdbaAv9De4CMYNUVQh4D7gJ8/ts9gFJrrcd/W5/LwxsIFAH/8nf3P2WMSUCfxyNirc0HHgV24oRwGbAcfR6PVkufvzbNnnAIYzlGxphE4A3gdmtteeBj1hluryH3h2CMOR/Ya61dHuxaQlwkMA54wlo7FqikSZe0Po+H5z+neQHOHzd9gAS+3vUqR6E9P3/hEMb5QL+A233990krGGOicIL4JWvtf/x3FzZ0t/i/7w1WfSFiMjDdGJOLc5rkDJxzn9383YSgz2Vr5AF51tov/LdfxwlnfR6PzJnAdmttkbW2HvgPzmdUn8ej09Lnr02zJxzCeCkwxD9SMBpnoMLsINcUEvznNZ8G1ltr/xDw0GzgWv/P1wJvdXRtocRa+1NrbV9r7QCcz9/H1tpvA/OBS/2b6TgehrV2D7DLGDPMf9c0YB36PB6pncAkY0y8//94w3HU5/HotPT5mw18xz+qehJQFtCdfcTCYtIPY8w3cc7ZuYBnrLUPBbei0GCMOQX4FFjNgXOd9+CcN34VyMJZWetya23TQQ3SDGPMFODH1trzjTGDcFrKqcAK4GprbW0Qy+v0jDFjcAbBRQPbgO/iNBr0eTwCxpifA1fgXDGxAvg+zvlMfR4PwRjzCjAFZ3WmQuABYBbNfP78f+j8BecUQBXwXWvtsqN+7XAIYxERkVAWDt3UIiIiIU1hLCIiEmQKYxERkSBTGIuIiASZwlhERCTIFMYiIiJBpjAWEREJMoWxiIhIkP0/Kro6Oeqd3zIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "epochs_range = range(EPOCHS)\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(epochs_range, history.history[\"accuracy\"], label='Training Accuracy')\n",
    "plt.plot(epochs_range, history.history[\"val_accuracy\"], label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't pickle local object 'PreprocessingLayer.make_adapt_function.<locals>.adapt_step'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4l/2mhtxr_d68z7kb_64f2vhw_40000gn/T/ipykernel_94120/2690240787.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"simple_model.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"a\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: Can't pickle local object 'PreprocessingLayer.make_adapt_function.<locals>.adapt_step'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open(\"simple_model.pkl\", \"a\") as f:\n",
    "\tpickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"DynamicStitch:0\", shape=(201,), dtype=float64)\n",
      "L2-error norm: 0.0021694660572233624\n",
      "\n",
      "================================================================================\n",
      "History\n",
      "================================================================================\n",
      "tf.Tensor(1.1413711309432983, shape=(), dtype=float64)\n",
      "tf.Tensor(1.0628472566604614, shape=(), dtype=float64)\n",
      "tf.Tensor(0.8951573967933655, shape=(), dtype=float64)\n",
      "tf.Tensor(0.8369911313056946, shape=(), dtype=float64)\n",
      "tf.Tensor(0.8366910219192505, shape=(), dtype=float64)\n",
      "tf.Tensor(0.80682373046875, shape=(), dtype=float64)\n",
      "tf.Tensor(0.8384192585945129, shape=(), dtype=float64)\n",
      "tf.Tensor(0.836879312992096, shape=(), dtype=float64)\n",
      "tf.Tensor(0.796928346157074, shape=(), dtype=float64)\n",
      "tf.Tensor(0.7547638416290283, shape=(), dtype=float64)\n",
      "tf.Tensor(0.7546207308769226, shape=(), dtype=float64)\n",
      "tf.Tensor(0.8116140365600586, shape=(), dtype=float64)\n",
      "tf.Tensor(0.7915165424346924, shape=(), dtype=float64)\n",
      "tf.Tensor(0.7557708621025085, shape=(), dtype=float64)\n",
      "tf.Tensor(0.7465876936912537, shape=(), dtype=float64)\n",
      "tf.Tensor(0.7291015386581421, shape=(), dtype=float64)\n",
      "tf.Tensor(0.6750473380088806, shape=(), dtype=float64)\n",
      "tf.Tensor(0.6406283974647522, shape=(), dtype=float64)\n",
      "tf.Tensor(0.6406137943267822, shape=(), dtype=float64)\n",
      "tf.Tensor(0.565081000328064, shape=(), dtype=float64)\n",
      "tf.Tensor(0.6160573959350586, shape=(), dtype=float64)\n",
      "tf.Tensor(0.5514022707939148, shape=(), dtype=float64)\n",
      "tf.Tensor(0.5173221826553345, shape=(), dtype=float64)\n",
      "tf.Tensor(0.5173006653785706, shape=(), dtype=float64)\n",
      "tf.Tensor(0.48308125138282776, shape=(), dtype=float64)\n",
      "tf.Tensor(0.4827887713909149, shape=(), dtype=float64)\n",
      "tf.Tensor(0.47068819403648376, shape=(), dtype=float64)\n",
      "tf.Tensor(0.46531298756599426, shape=(), dtype=float64)\n",
      "tf.Tensor(0.4591205418109894, shape=(), dtype=float64)\n",
      "tf.Tensor(0.6335265636444092, shape=(), dtype=float64)\n",
      "tf.Tensor(0.5677297115325928, shape=(), dtype=float64)\n",
      "tf.Tensor(0.4568893611431122, shape=(), dtype=float64)\n",
      "tf.Tensor(0.44589078426361084, shape=(), dtype=float64)\n",
      "tf.Tensor(0.4288974702358246, shape=(), dtype=float64)\n",
      "tf.Tensor(0.4261881709098816, shape=(), dtype=float64)\n",
      "tf.Tensor(0.4170165956020355, shape=(), dtype=float64)\n",
      "tf.Tensor(0.41538873314857483, shape=(), dtype=float64)\n",
      "tf.Tensor(0.41037821769714355, shape=(), dtype=float64)\n",
      "tf.Tensor(0.46038275957107544, shape=(), dtype=float64)\n",
      "tf.Tensor(0.40980005264282227, shape=(), dtype=float64)\n",
      "tf.Tensor(0.3943011462688446, shape=(), dtype=float64)\n",
      "tf.Tensor(0.4072774648666382, shape=(), dtype=float64)\n",
      "tf.Tensor(0.392390638589859, shape=(), dtype=float64)\n",
      "tf.Tensor(0.3759608268737793, shape=(), dtype=float64)\n",
      "tf.Tensor(0.37518858909606934, shape=(), dtype=float64)\n",
      "tf.Tensor(0.3644692003726959, shape=(), dtype=float64)\n",
      "tf.Tensor(0.3644348680973053, shape=(), dtype=float64)\n",
      "tf.Tensor(0.3560846745967865, shape=(), dtype=float64)\n",
      "tf.Tensor(0.35582637786865234, shape=(), dtype=float64)\n",
      "tf.Tensor(0.3471861481666565, shape=(), dtype=float64)\n",
      "tf.Tensor(0.3460201025009155, shape=(), dtype=float64)\n",
      "tf.Tensor(0.3220829963684082, shape=(), dtype=float64)\n",
      "tf.Tensor(0.5266276597976685, shape=(), dtype=float64)\n",
      "tf.Tensor(0.3009036183357239, shape=(), dtype=float64)\n",
      "tf.Tensor(0.652974009513855, shape=(), dtype=float64)\n",
      "tf.Tensor(0.37006303668022156, shape=(), dtype=float64)\n",
      "tf.Tensor(0.2878453731536865, shape=(), dtype=float64)\n",
      "tf.Tensor(0.2654655873775482, shape=(), dtype=float64)\n",
      "tf.Tensor(0.3462235927581787, shape=(), dtype=float64)\n",
      "tf.Tensor(0.2653716206550598, shape=(), dtype=float64)\n",
      "tf.Tensor(0.24276074767112732, shape=(), dtype=float64)\n",
      "tf.Tensor(0.24085241556167603, shape=(), dtype=float64)\n",
      "tf.Tensor(0.2343277633190155, shape=(), dtype=float64)\n",
      "tf.Tensor(0.23290984332561493, shape=(), dtype=float64)\n",
      "tf.Tensor(0.23030923306941986, shape=(), dtype=float64)\n",
      "tf.Tensor(0.23006196320056915, shape=(), dtype=float64)\n",
      "tf.Tensor(0.22657164931297302, shape=(), dtype=float64)\n",
      "tf.Tensor(0.2265622764825821, shape=(), dtype=float64)\n",
      "tf.Tensor(0.2243344932794571, shape=(), dtype=float64)\n",
      "tf.Tensor(0.2360035628080368, shape=(), dtype=float64)\n",
      "tf.Tensor(0.22433586418628693, shape=(), dtype=float64)\n",
      "tf.Tensor(0.22195018827915192, shape=(), dtype=float64)\n",
      "tf.Tensor(0.22270578145980835, shape=(), dtype=float64)\n",
      "tf.Tensor(0.21882319450378418, shape=(), dtype=float64)\n",
      "tf.Tensor(0.25082001090049744, shape=(), dtype=float64)\n",
      "tf.Tensor(0.21784716844558716, shape=(), dtype=float64)\n",
      "tf.Tensor(0.21542909741401672, shape=(), dtype=float64)\n",
      "tf.Tensor(0.21751460433006287, shape=(), dtype=float64)\n",
      "tf.Tensor(0.2146340310573578, shape=(), dtype=float64)\n",
      "tf.Tensor(0.21514391899108887, shape=(), dtype=float64)\n",
      "tf.Tensor(0.213258296251297, shape=(), dtype=float64)\n",
      "tf.Tensor(0.2121734619140625, shape=(), dtype=float64)\n",
      "tf.Tensor(0.21196527779102325, shape=(), dtype=float64)\n",
      "tf.Tensor(0.21225905418395996, shape=(), dtype=float64)\n",
      "tf.Tensor(0.2118854522705078, shape=(), dtype=float64)\n",
      "tf.Tensor(0.21163086593151093, shape=(), dtype=float64)\n",
      "tf.Tensor(0.21160835027694702, shape=(), dtype=float64)\n",
      "tf.Tensor(0.2113567441701889, shape=(), dtype=float64)\n",
      "tf.Tensor(0.2121252417564392, shape=(), dtype=float64)\n",
      "tf.Tensor(0.2113628387451172, shape=(), dtype=float64)\n",
      "tf.Tensor(0.21109208464622498, shape=(), dtype=float64)\n",
      "tf.Tensor(0.21046079695224762, shape=(), dtype=float64)\n",
      "tf.Tensor(0.21046194434165955, shape=(), dtype=float64)\n",
      "tf.Tensor(0.21003760397434235, shape=(), dtype=float64)\n",
      "tf.Tensor(0.21146704256534576, shape=(), dtype=float64)\n",
      "tf.Tensor(0.209678515791893, shape=(), dtype=float64)\n",
      "tf.Tensor(0.20823456346988678, shape=(), dtype=float64)\n",
      "tf.Tensor(0.2084645926952362, shape=(), dtype=float64)\n",
      "tf.Tensor(0.20938657224178314, shape=(), dtype=float64)\n",
      "tf.Tensor(0.20785683393478394, shape=(), dtype=float64)\n",
      "tf.Tensor(0.21073086559772491, shape=(), dtype=float64)\n",
      "tf.Tensor(0.20735986530780792, shape=(), dtype=float64)\n",
      "tf.Tensor(0.20770952105522156, shape=(), dtype=float64)\n",
      "tf.Tensor(0.20710371434688568, shape=(), dtype=float64)\n",
      "tf.Tensor(0.20720385015010834, shape=(), dtype=float64)\n",
      "tf.Tensor(0.20680145919322968, shape=(), dtype=float64)\n",
      "tf.Tensor(0.20658598840236664, shape=(), dtype=float64)\n",
      "tf.Tensor(0.20576831698417664, shape=(), dtype=float64)\n",
      "tf.Tensor(0.2052038013935089, shape=(), dtype=float64)\n",
      "tf.Tensor(0.20633099973201752, shape=(), dtype=float64)\n",
      "tf.Tensor(0.20517896115779877, shape=(), dtype=float64)\n",
      "tf.Tensor(0.20467232167720795, shape=(), dtype=float64)\n",
      "tf.Tensor(0.20694735646247864, shape=(), dtype=float64)\n",
      "tf.Tensor(0.20467494428157806, shape=(), dtype=float64)\n",
      "tf.Tensor(0.20411524176597595, shape=(), dtype=float64)\n",
      "tf.Tensor(0.20410706102848053, shape=(), dtype=float64)\n",
      "tf.Tensor(0.20382127165794373, shape=(), dtype=float64)\n",
      "tf.Tensor(0.2044132500886917, shape=(), dtype=float64)\n",
      "tf.Tensor(0.20389562845230103, shape=(), dtype=float64)\n",
      "tf.Tensor(0.20356690883636475, shape=(), dtype=float64)\n",
      "tf.Tensor(0.20570243895053864, shape=(), dtype=float64)\n",
      "tf.Tensor(0.20356570184230804, shape=(), dtype=float64)\n",
      "tf.Tensor(0.2032395601272583, shape=(), dtype=float64)\n",
      "tf.Tensor(0.20320452749729156, shape=(), dtype=float64)\n",
      "tf.Tensor(0.20301856100559235, shape=(), dtype=float64)\n",
      "tf.Tensor(0.20251919329166412, shape=(), dtype=float64)\n",
      "tf.Tensor(0.20186829566955566, shape=(), dtype=float64)\n",
      "tf.Tensor(0.21151216328144073, shape=(), dtype=float64)\n",
      "tf.Tensor(0.2020021229982376, shape=(), dtype=float64)\n",
      "tf.Tensor(0.2011878490447998, shape=(), dtype=float64)\n",
      "tf.Tensor(0.2059430629014969, shape=(), dtype=float64)\n",
      "tf.Tensor(0.20098942518234253, shape=(), dtype=float64)\n",
      "tf.Tensor(0.2004251778125763, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19996054470539093, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1994878500699997, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19949670135974884, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1995469182729721, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19922897219657898, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19891953468322754, shape=(), dtype=float64)\n",
      "tf.Tensor(0.20107734203338623, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1988798975944519, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1985304057598114, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19851188361644745, shape=(), dtype=float64)\n",
      "tf.Tensor(0.21002456545829773, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1992522031068802, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19838254153728485, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1984959989786148, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19819365441799164, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19792526960372925, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1997099071741104, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19792558252811432, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19783473014831543, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1977086216211319, shape=(), dtype=float64)\n",
      "tf.Tensor(0.197496697306633, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19748325645923615, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19736286997795105, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19713880121707916, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19711266458034515, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1969335824251175, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19692102074623108, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19681701064109802, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19723179936408997, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19681833684444427, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19670654833316803, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19650183618068695, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1964811384677887, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19631899893283844, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1962595283985138, shape=(), dtype=float64)\n",
      "tf.Tensor(0.201448455452919, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19624438881874084, shape=(), dtype=float64)\n",
      "tf.Tensor(0.196259006857872, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19615201652050018, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19725459814071655, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19554650783538818, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19520166516304016, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19534656405448914, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19498339295387268, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19441691040992737, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1943618357181549, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19393882155418396, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19490927457809448, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19378747045993805, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19505321979522705, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19352446496486664, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1937142312526703, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19347482919692993, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1941290944814682, shape=(), dtype=float64)\n",
      "tf.Tensor(0.193343847990036, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19314706325531006, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1937643438577652, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19314219057559967, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1928679496049881, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19263887405395508, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19259154796600342, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19215825200080872, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19583791494369507, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19210070371627808, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19175656139850616, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1916314959526062, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1916315108537674, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19600600004196167, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19154740869998932, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19093036651611328, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19087262451648712, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19076579809188843, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19127248227596283, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19075699150562286, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19066408276557922, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19125787913799286, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19065141677856445, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19043193757534027, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1905485987663269, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19038191437721252, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19027002155780792, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19019824266433716, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19008700549602509, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19014069437980652, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1900027096271515, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19270388782024384, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1899835616350174, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1898888647556305, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19010144472122192, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18984194099903107, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1897428184747696, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18973948061466217, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18964636325836182, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1900038868188858, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18964503705501556, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18959805369377136, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18959802389144897, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18956215679645538, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18968257308006287, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18954694271087646, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18955087661743164, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18952728807926178, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18941210210323334, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1896209567785263, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18938378989696503, shape=(), dtype=float64)\n",
      "tf.Tensor(0.189284086227417, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18971362709999084, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18928320705890656, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18917222321033478, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18932214379310608, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18903732299804688, shape=(), dtype=float64)\n",
      "tf.Tensor(0.2351406067609787, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18905718624591827, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18899911642074585, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1889488697052002, shape=(), dtype=float64)\n",
      "tf.Tensor(0.188948854804039, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1889033168554306, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1888972669839859, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18887731432914734, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1888316422700882, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18896040320396423, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18883058428764343, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18879680335521698, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18910664319992065, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18879438936710358, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18876489996910095, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18898776173591614, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1887572854757309, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18873950839042664, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18882009387016296, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18873606622219086, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1887202262878418, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18872013688087463, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18869450688362122, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18864122033119202, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18864135444164276, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18955250084400177, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18862619996070862, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18857955932617188, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1894807666540146, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18857954442501068, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18854930996894836, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18862850964069366, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18854349851608276, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1885318160057068, shape=(), dtype=float64)\n",
      "tf.Tensor(0.188585102558136, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18853013217449188, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18852077424526215, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1885100156068802, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18850918114185333, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18848207592964172, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1885649710893631, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18847432732582092, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18843817710876465, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18838182091712952, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18838030099868774, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1885489672422409, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1883644461631775, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18831998109817505, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18885597586631775, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1883196085691452, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18830163776874542, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18842823803424835, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18830031156539917, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18829067051410675, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1883344054222107, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18828848004341125, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18830111622810364, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18828131258487701, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18827266991138458, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18827027082443237, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1882539987564087, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18867461383342743, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1882462054491043, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18838302791118622, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18824149668216705, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18825122714042664, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18823736906051636, shape=(), dtype=float64)\n",
      "tf.Tensor(0.6991363763809204, shape=(), dtype=float64)\n",
      "tf.Tensor(0.191087543964386, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18823547661304474, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18821583688259125, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1883300542831421, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18821462988853455, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1881871372461319, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18818694353103638, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1881650686264038, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18814927339553833, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18814270198345184, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18812231719493866, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18809926509857178, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18809892237186432, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1880882978439331, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18805396556854248, shape=(), dtype=float64)\n",
      "tf.Tensor(0.188373401761055, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18802861869335175, shape=(), dtype=float64)\n",
      "tf.Tensor(0.43802812695503235, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1880108267068863, shape=(), dtype=float64)\n",
      "tf.Tensor(0.2381558120250702, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18799474835395813, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1926872283220291, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1879449039697647, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19099555909633636, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1885950267314911, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18792201578617096, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18784953653812408, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18816189467906952, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18783557415008545, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18779565393924713, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18805083632469177, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18779368698596954, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18790537118911743, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18776699900627136, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18774980306625366, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18821200728416443, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18774926662445068, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18774062395095825, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18774642050266266, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18773674964904785, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18773260712623596, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18773235380649567, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1877298355102539, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18772797286510468, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18772707879543304, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18772509694099426, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18772540986537933, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18772338330745697, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18771959841251373, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18781036138534546, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18771883845329285, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18771368265151978, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18778547644615173, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18771332502365112, shape=(), dtype=float64)\n",
      "tf.Tensor(0.19025829434394836, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18771298229694366, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18771560490131378, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1877138912677765, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18771114945411682, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18823112547397614, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18770934641361237, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18805591762065887, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1877586394548416, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1877075880765915, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1877252757549286, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18770501017570496, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1876956820487976, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18770772218704224, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1876993477344513, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1876761019229889, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18771551549434662, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18769238889217377, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18765883147716522, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18771778047084808, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18770983815193176, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1876874715089798, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18766066431999207, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1876336932182312, shape=(), dtype=float64)\n",
      "tf.Tensor(0.187702015042305, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1876363605260849, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18758612871170044, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18784643709659576, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18762622773647308, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18758593499660492, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18757158517837524, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1876462697982788, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18757005035877228, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18753957748413086, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1875583678483963, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1875593513250351, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18746857345104218, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18855836987495422, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1874433159828186, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1895970106124878, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18743501603603363, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18737901747226715, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18796029686927795, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1873709261417389, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1873958706855774, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18736013770103455, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18731975555419922, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18794795870780945, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18731608986854553, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18727658689022064, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18727687001228333, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18784520030021667, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18726740777492523, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18722334504127502, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1881241649389267, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18722166121006012, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18719445168972015, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18754921853542328, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18719442188739777, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18718202412128448, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18718495965003967, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1871740221977234, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18715347349643707, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1870908886194229, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18917785584926605, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18709024786949158, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18793031573295593, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18705545365810394, shape=(), dtype=float64)\n",
      "tf.Tensor(0.187642902135849, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1870815008878708, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18703490495681763, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18750789761543274, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18711057305335999, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18701493740081787, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18698036670684814, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18694673478603363, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18690063059329987, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1874137967824936, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18690061569213867, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18686102330684662, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18711258471012115, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1868516057729721, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18681055307388306, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1869901716709137, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18680305778980255, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18674597144126892, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18672554194927216, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18669594824314117, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18665377795696259, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18665067851543427, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18661406636238098, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18654431402683258, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18732431530952454, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18654431402683258, shape=(), dtype=float64)\n",
      "tf.Tensor(0.186510369181633, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18652573227882385, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18648649752140045, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1864672750234604, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18648210167884827, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18645553290843964, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18644599616527557, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1865125298500061, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1864442676305771, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1864384263753891, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1864524632692337, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18643654882907867, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18643368780612946, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18643873929977417, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1864323765039444, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18643002212047577, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18643346428871155, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1864289492368698, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1864258348941803, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1864325851202011, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18642428517341614, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18642038106918335, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18642419576644897, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1864183396100998, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18641330301761627, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18640843033790588, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18640774488449097, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18640409409999847, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18648140132427216, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18640388548374176, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1863950490951538, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1863245964050293, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1929660439491272, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1863202452659607, shape=(), dtype=float64)\n",
      "tf.Tensor(0.5945192575454712, shape=(), dtype=float64)\n",
      "tf.Tensor(0.215043306350708, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18631848692893982, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18630564212799072, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18630552291870117, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18822281062602997, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1863027811050415, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1863628625869751, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18629854917526245, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18619999289512634, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18619737029075623, shape=(), dtype=float64)\n",
      "tf.Tensor(0.5531148314476013, shape=(), dtype=float64)\n",
      "tf.Tensor(0.2682974636554718, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18619707226753235, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1861734241247177, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18617308139801025, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18643954396247864, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1861802190542221, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18616512417793274, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1861669421195984, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18614636361598969, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18620966374874115, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18610987067222595, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1860479712486267, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1860479712486267, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18594016134738922, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1863342523574829, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1859234869480133, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18584777414798737, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18600739538669586, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18582329154014587, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18574877083301544, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18674135208129883, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1857486516237259, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18564148247241974, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18571360409259796, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18558579683303833, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18553420901298523, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1857895702123642, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1855323314666748, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18549908697605133, shape=(), dtype=float64)\n",
      "tf.Tensor(0.185817688703537, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18549634516239166, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18547527492046356, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18549147248268127, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18546271324157715, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18545272946357727, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18559983372688293, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1854526400566101, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18544423580169678, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18544599413871765, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18543784320354462, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18541863560676575, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1853897124528885, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18645980954170227, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1853894740343094, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1853838711977005, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1853838413953781, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1853804737329483, shape=(), dtype=float64)\n",
      "tf.Tensor(0.185380220413208, shape=(), dtype=float64)\n",
      "tf.Tensor(0.185377836227417, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18537630140781403, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18537284433841705, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18592965602874756, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18537281453609467, shape=(), dtype=float64)\n",
      "tf.Tensor(0.185371994972229, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1853821724653244, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18537193536758423, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18537075817584991, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18537065386772156, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18536970019340515, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1853676587343216, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18536731600761414, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18536610901355743, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18536418676376343, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18536683917045593, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18536308407783508, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18536178767681122, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18536750972270966, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18536144495010376, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18536148965358734, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1853606402873993, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18535974621772766, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18535999953746796, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18535929918289185, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18535813689231873, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18536101281642914, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18535754084587097, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18535739183425903, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18535687029361725, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18535642325878143, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1853562742471695, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18535582721233368, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18535570800304413, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18535517156124115, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18535739183425903, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18535515666007996, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18535485863685608, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18535475432872772, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1853545904159546, shape=(), dtype=float64)\n",
      "tf.Tensor(0.185354083776474, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18537382781505585, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1853540539741516, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18535281717777252, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1853513866662979, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18535125255584717, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18535006046295166, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18535661697387695, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18534989655017853, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18534928560256958, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1853678673505783, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1853492707014084, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1853477507829666, shape=(), dtype=float64)\n",
      "tf.Tensor(0.1854650378227234, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18534773588180542, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18534407019615173, shape=(), dtype=float64)\n",
      "tf.Tensor(0.186113178730011, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18534375727176666, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18563881516456604, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18534332513809204, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18542851507663727, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18534323573112488, shape=(), dtype=float64)\n",
      "tf.Tensor(0.185342475771904, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18534280359745026, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18534159660339355, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18534135818481445, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18534104526042938, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18534116446971893, shape=(), dtype=float64)\n",
      "tf.Tensor(0.18543383479118347, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "#! /usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# vim:fenc=utf-8\n",
    "#\n",
    "# Copyright © 2019 Pi-Yueh Chuang <pychuang@gwu.edu>\n",
    "#\n",
    "# Distributed under terms of the MIT license.\n",
    "\n",
    "\"\"\"An example of using tfp.optimizer.lbfgs_minimize to optimize a TensorFlow model.\n",
    "\n",
    "This code shows a naive way to wrap a tf.keras.Model and optimize it with the L-BFGS\n",
    "optimizer from TensorFlow Probability.\n",
    "\n",
    "Python interpreter version: 3.6.9\n",
    "TensorFlow version: 2.0.0\n",
    "TensorFlow Probability version: 0.8.0\n",
    "NumPy version: 1.17.2\n",
    "Matplotlib version: 3.1.1\n",
    "\"\"\"\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from matplotlib import pyplot\n",
    "\n",
    "def function_factory(model, loss, train_x, train_y):\n",
    "    \"\"\"A factory to create a function required by tfp.optimizer.lbfgs_minimize.\n",
    "\n",
    "    Args:\n",
    "        model [in]: an instance of `tf.keras.Model` or its subclasses.\n",
    "        loss [in]: a function with signature loss_value = loss(pred_y, true_y).\n",
    "        train_x [in]: the input part of training data.\n",
    "        train_y [in]: the output part of training data.\n",
    "\n",
    "    Returns:\n",
    "        A function that has a signature of:\n",
    "            loss_value, gradients = f(model_parameters).\n",
    "    \"\"\"\n",
    "\n",
    "    # obtain the shapes of all trainable parameters in the model\n",
    "    shapes = tf.shape_n(model.trainable_variables)\n",
    "    n_tensors = len(shapes)\n",
    "\n",
    "    # we'll use tf.dynamic_stitch and tf.dynamic_partition later, so we need to\n",
    "    # prepare required information first\n",
    "    count = 0\n",
    "    idx = [] # stitch indices\n",
    "    part = [] # partition indices\n",
    "\n",
    "    for i, shape in enumerate(shapes):\n",
    "        n = numpy.product(shape)\n",
    "        idx.append(tf.reshape(tf.range(count, count+n, dtype=tf.int32), shape))\n",
    "        part.extend([i]*n)\n",
    "        count += n\n",
    "\n",
    "    part = tf.constant(part)\n",
    "\n",
    "    @tf.function\n",
    "    def assign_new_model_parameters(params_1d):\n",
    "        \"\"\"A function updating the model's parameters with a 1D tf.Tensor.\n",
    "\n",
    "        Args:\n",
    "            params_1d [in]: a 1D tf.Tensor representing the model's trainable parameters.\n",
    "        \"\"\"\n",
    "\n",
    "        params = tf.dynamic_partition(params_1d, part, n_tensors)\n",
    "        for i, (shape, param) in enumerate(zip(shapes, params)):\n",
    "            model.trainable_variables[i].assign(tf.reshape(param, shape))\n",
    "\n",
    "    # now create a function that will be returned by this factory\n",
    "    @tf.function\n",
    "    def f(params_1d):\n",
    "        \"\"\"A function that can be used by tfp.optimizer.lbfgs_minimize.\n",
    "\n",
    "        This function is created by function_factory.\n",
    "\n",
    "        Args:\n",
    "           params_1d [in]: a 1D tf.Tensor.\n",
    "\n",
    "        Returns:\n",
    "            A scalar loss and the gradients w.r.t. the `params_1d`.\n",
    "        \"\"\"\n",
    "\n",
    "        # use GradientTape so that we can calculate the gradient of loss w.r.t. parameters\n",
    "        with tf.GradientTape() as tape:\n",
    "            # update the parameters in the model\n",
    "            assign_new_model_parameters(params_1d)\n",
    "            # calculate the loss\n",
    "            loss_value = loss(model(train_x, training=True), train_y)\n",
    "\n",
    "        # calculate gradients and convert to 1D tf.Tensor\n",
    "        grads = tape.gradient(loss_value, model.trainable_variables)\n",
    "        grads = tf.dynamic_stitch(idx, grads)\n",
    "\n",
    "        # print out iteration & loss\n",
    "        f.iter.assign_add(1)\n",
    "        # tf.print(\"Iter:\", f.iter, \"loss:\", loss_value)\n",
    "        print(grads)\n",
    "\n",
    "        # store loss value so we can retrieve later\n",
    "        tf.py_function(f.history.append, inp=[loss_value], Tout=[])\n",
    "\n",
    "        return loss_value, grads\n",
    "\n",
    "    # store these information as members so we can use them outside the scope\n",
    "    f.iter = tf.Variable(0)\n",
    "    f.idx = idx\n",
    "    f.part = part\n",
    "    f.shapes = shapes\n",
    "    f.assign_new_model_parameters = assign_new_model_parameters\n",
    "    f.history = []\n",
    "\n",
    "    return f\n",
    "\n",
    "def plot_helper(inputs, outputs, title, fname):\n",
    "    \"\"\"Plot helper\"\"\"\n",
    "    pyplot.figure()\n",
    "    pyplot.tricontourf(inputs[:, 0], inputs[:, 1], outputs.flatten(), 100)\n",
    "    pyplot.xlabel(\"x\")\n",
    "    pyplot.ylabel(\"y\")\n",
    "    pyplot.title(title)\n",
    "    pyplot.colorbar()\n",
    "    pyplot.savefig(fname)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # use float64 by default\n",
    "    tf.keras.backend.set_floatx(\"float64\")\n",
    "\n",
    "    # prepare prediction model, loss function, and the function passed to L-BFGS solver\n",
    "    pred_model = tf.keras.Sequential(\n",
    "        [normalizer,\n",
    "         tf.keras.layers.Dense(9, \"relu\"),\n",
    "         tf.keras.layers.Dense(9, \"relu\"),\n",
    "         tf.keras.layers.Dense(3, \"sigmoid\")])\n",
    "\n",
    "    func = function_factory(pred_model, tf.keras.losses.BinaryCrossentropy(), professor['training']['questions'], professor['training']['answers'])\n",
    "\n",
    "    # convert initial model parameters to a 1D tf.Tensor\n",
    "    init_params = tf.dynamic_stitch(func.idx, pred_model.trainable_variables)\n",
    "\n",
    "    # train the model with L-BFGS solver\n",
    "    results = tfp.optimizer.lbfgs_minimize(\n",
    "        value_and_gradients_function=func, initial_position=init_params, max_iterations=500)\n",
    "\n",
    "    # after training, the final optimized parameters are still in results.position\n",
    "    # so we have to manually put them back to the model\n",
    "    func.assign_new_model_parameters(results.position)\n",
    "\n",
    "    # do some prediction\n",
    "    pred_outs = pred_model.predict(professor['test']['questions'])\n",
    "    print(\"L2-error norm: {}\".format(numpy.linalg.norm(err)/numpy.sqrt(11)))\n",
    "\n",
    "\n",
    "    # print out history\n",
    "    print(\"\\n\"+\"=\"*80)\n",
    "    print(\"History\")\n",
    "    print(\"=\"*80)\n",
    "    print(*func.history, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>u</th>\n",
       "      <th>g</th>\n",
       "      <th>r</th>\n",
       "      <th>i</th>\n",
       "      <th>z</th>\n",
       "      <th>redshift</th>\n",
       "      <th>class_GALAXY</th>\n",
       "      <th>class_QSO</th>\n",
       "      <th>class_STAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8000</th>\n",
       "      <td>8000</td>\n",
       "      <td>0.190349</td>\n",
       "      <td>-0.599724</td>\n",
       "      <td>-0.079026</td>\n",
       "      <td>-0.204305</td>\n",
       "      <td>-0.154887</td>\n",
       "      <td>-0.110684</td>\n",
       "      <td>-0.030056</td>\n",
       "      <td>-0.370001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8001</th>\n",
       "      <td>8001</td>\n",
       "      <td>0.188651</td>\n",
       "      <td>-0.598305</td>\n",
       "      <td>0.745707</td>\n",
       "      <td>0.702019</td>\n",
       "      <td>0.629892</td>\n",
       "      <td>0.602372</td>\n",
       "      <td>0.601848</td>\n",
       "      <td>-0.367239</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8002</th>\n",
       "      <td>8002</td>\n",
       "      <td>0.190667</td>\n",
       "      <td>-0.604786</td>\n",
       "      <td>1.004693</td>\n",
       "      <td>0.648648</td>\n",
       "      <td>0.312791</td>\n",
       "      <td>0.092810</td>\n",
       "      <td>-0.032583</td>\n",
       "      <td>-0.091988</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8003</th>\n",
       "      <td>8003</td>\n",
       "      <td>0.191552</td>\n",
       "      <td>-0.603357</td>\n",
       "      <td>0.394077</td>\n",
       "      <td>1.518491</td>\n",
       "      <td>1.645257</td>\n",
       "      <td>1.595851</td>\n",
       "      <td>1.568480</td>\n",
       "      <td>3.531147</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8004</th>\n",
       "      <td>8004</td>\n",
       "      <td>0.191230</td>\n",
       "      <td>-0.598623</td>\n",
       "      <td>-1.215336</td>\n",
       "      <td>-1.586335</td>\n",
       "      <td>-1.722162</td>\n",
       "      <td>-1.761351</td>\n",
       "      <td>-1.850619</td>\n",
       "      <td>-0.164494</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0        ra       dec         u         g         r         i  \\\n",
       "8000        8000  0.190349 -0.599724 -0.079026 -0.204305 -0.154887 -0.110684   \n",
       "8001        8001  0.188651 -0.598305  0.745707  0.702019  0.629892  0.602372   \n",
       "8002        8002  0.190667 -0.604786  1.004693  0.648648  0.312791  0.092810   \n",
       "8003        8003  0.191552 -0.603357  0.394077  1.518491  1.645257  1.595851   \n",
       "8004        8004  0.191230 -0.598623 -1.215336 -1.586335 -1.722162 -1.761351   \n",
       "\n",
       "             z  redshift  class_GALAXY  class_QSO  class_STAR  \n",
       "8000 -0.030056 -0.370001           0.1        0.1         0.9  \n",
       "8001  0.601848 -0.367239           0.1        0.1         0.9  \n",
       "8002 -0.032583 -0.091988           0.9        0.1         0.1  \n",
       "8003  1.568480  3.531147           0.1        0.9         0.1  \n",
       "8004 -1.850619 -0.164494           0.9        0.1         0.1  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 3), dtype=float64, numpy=\n",
       "array([[5.27983390e-028, 3.42950138e-204, 1.00000000e+000],\n",
       "       [9.41174609e-008, 2.05124057e-130, 1.00000000e+000],\n",
       "       [1.00000000e+000, 8.30128819e-203, 7.03311393e-081],\n",
       "       [8.75108805e-263, 0.00000000e+000, 5.87449560e-301],\n",
       "       [1.00000000e+000, 0.00000000e+000, 2.87483878e-166]])>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_model.__call__(professor['evaluation']['questions'].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4l/2mhtxr_d68z7kb_64f2vhw_40000gn/T/ipykernel_12657/1488626702.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mepochs_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lower right'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "epochs_range = range(EPOCHS)\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(epochs_range, func.history[\"accuracy\"], label='Training Accuracy')\n",
    "plt.plot(epochs_range, func.history[\"val_accuracy\"], label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "df43c9307c76c4cd9923f314021df753cfc5fee661cd973f404bb263823edc85"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('.venv': poetry)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
